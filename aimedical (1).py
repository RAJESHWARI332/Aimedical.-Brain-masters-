# -*- coding: utf-8 -*-
"""Aimedical.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TQLsG_srbuoTWv64HAA-wF_fVd6qw9YB
"""



# AI Medical Prescription Verification System
# Features: Prescription Verification, Medical Chatbot, Language Translation, Image Analysis
# Powered by IBM Granite 3.3 2B + Advanced OCR
# Ready to run in Google Colab

# Install required packages
!pip install -q gradio transformers torch pillow googletrans==3.1.0a0 huggingface_hub accelerate pytesseract easyocr opencv-python-headless

# Install Tesseract OCR
!apt-get install -q tesseract-ocr
!apt-get install -q tesseract-ocr-hin tesseract-ocr-tam tesseract-ocr-tel

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from PIL import Image
from googletrans import Translator, LANGUAGES
import pytesseract
import easyocr
import cv2
import numpy as np
import warnings
import re
from datetime import datetime
warnings.filterwarnings('ignore')

print("üîß Initializing AI Medical Prescription Verification System...")

# Initialize the IBM Granite model
model_name = "ibm-granite/granite-3.0-2b-instruct"
print(f"üì• Loading {model_name}...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto",
    low_cpu_mem_usage=True
)

# Initialize translator
translator = Translator()

# Initialize EasyOCR reader with multiple languages
print("üîß Loading OCR engines...")
reader = easyocr.Reader(['en', 'hi'], gpu=torch.cuda.is_available())

# Initialize image analysis model
print("üîß Loading image analysis model...")
image_analyzer = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")

# Language mapping with Indian languages
LANGUAGE_MAP = {
    "English": "en",
    "Hindi": "hi",
    "Tamil": "ta",
    "Telugu": "te",
    "Bengali": "bn",
    "Marathi": "mr",
    "Gujarati": "gu",
    "Kannada": "kn",
    "Malayalam": "ml",
    "Punjabi": "pa",
    "Urdu": "ur",
    "Spanish": "es",
    "French": "fr",
    "German": "de",
    "Chinese": "zh-cn",
    "Arabic": "ar"
}

# Common medication database (sample)
MEDICATION_DATABASE = {
    "paracetamol": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "ibuprofen": {"max_dose": "3200mg/day", "category": "NSAID", "interactions": "aspirin, blood thinners"},
    "amoxicillin": {"max_dose": "3000mg/day", "category": "Antibiotic", "interactions": "methotrexate"},
    "metformin": {"max_dose": "2550mg/day", "category": "Antidiabetic", "interactions": "alcohol, iodinated contrast"},
    "aspirin": {"max_dose": "4000mg/day", "category": "Analgesic/Antiplatelet", "interactions": "ibuprofen, warfarin"},
    "omeprazole": {"max_dose": "40mg/day", "category": "PPI", "interactions": "clopidogrel"},
    "atorvastatin": {"max_dose": "80mg/day", "category": "Statin", "interactions": "grapefruit juice"},
    "lisinopril": {"max_dose": "80mg/day", "category": "ACE Inhibitor", "interactions": "potassium supplements"},
}

def generate_response(prompt, max_length=512, system_context=None):
    """Generate response using IBM Granite model"""

    if system_context is None:
        system_context = """You are an expert medical AI assistant specializing in prescription verification and medication safety.
Provide accurate, detailed medical information while always emphasizing the importance of consulting healthcare professionals."""

    full_prompt = f"{system_context}\n\nUser: {prompt}\nAssistant:"

    inputs = tokenizer(full_prompt, return_tensors="pt", truncation=True, max_length=2048)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_length,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    if "Assistant:" in response:
        response = response.split("Assistant:")[-1].strip()

    return response

def translate_text(text, target_lang):
    """Translate text to target language"""
    try:
        if target_lang == "en" or not text:
            return text
        translated = translator.translate(text, dest=target_lang)
        return translated.text
    except Exception as e:
        return text  # Return original if translation fails

def extract_text_from_image(image):
    """Extract text from prescription image using OCR"""
    try:
        # Convert PIL image to numpy array
        img_array = np.array(image)

        # Use EasyOCR
        results = reader.readtext(img_array)
        extracted_text = " ".join([result[1] for result in results])

        # Also try Tesseract as backup
        tesseract_text = pytesseract.image_to_string(image)

        # Combine both results
        combined_text = extracted_text + " " + tesseract_text

        return combined_text.strip()
    except Exception as e:
        return f"Error extracting text: {str(e)}"

def analyze_prescription(text):
    """Analyze prescription text for medications and dosages"""

    medications_found = []

    # Search for known medications
    text_lower = text.lower()
    for med_name, med_info in MEDICATION_DATABASE.items():
        if med_name in text_lower:
            medications_found.append({
                "name": med_name.title(),
                "info": med_info
            })

    # Extract dosage patterns (e.g., 500mg, 10ml)
    dosage_pattern = r'\d+\s*(mg|ml|g|mcg|units?)'
    dosages = re.findall(dosage_pattern, text_lower)

    # Extract frequency patterns (e.g., twice daily, 2x/day)
    frequency_pattern = r'(once|twice|thrice|\d+x?)\s*(daily|per day|/day|a day)'
    frequencies = re.findall(frequency_pattern, text_lower)

    return {
        "medications": medications_found,
        "dosages": dosages,
        "frequencies": frequencies,
        "raw_text": text
    }

def verify_prescription(image, language):
    """Complete prescription verification pipeline"""

    if image is None:
        return "‚ùå Please upload a prescription image.", "", ""

    lang_code = LANGUAGE_MAP.get(language, "en")

    # Step 1: Extract text from image
    status = "üìÑ Extracting text from prescription..."
    extracted_text = extract_text_from_image(image)

    if not extracted_text or len(extracted_text) < 10:
        error_msg = "‚ö†Ô∏è Could not extract sufficient text from the image. Please ensure:\n- Image is clear and well-lit\n- Text is readable\n- Prescription is in focus"
        return translate_text(error_msg, lang_code), "", ""

    # Step 2: Analyze prescription
    analysis = analyze_prescription(extracted_text)

    # Step 3: Generate verification report
    verification_prompt = f"""Analyze this prescription text and provide a detailed verification report:

Extracted Text: {extracted_text}

Medications Found: {[m['name'] for m in analysis['medications']]}

Please provide:
1. List of identified medications
2. Dosage verification (safe/unsafe ranges)
3. Potential drug interactions
4. Important warnings or precautions
5. Recommendations

Format the response clearly with sections."""

    verification_report = generate_response(verification_prompt, max_length=800)

    # Step 4: Create structured output
    output = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          PRESCRIPTION VERIFICATION REPORT                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìÖ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{'='*60}
üìã EXTRACTED TEXT:
{'='*60}
{extracted_text}

{'='*60}
üíä IDENTIFIED MEDICATIONS:
{'='*60}
"""

    if analysis['medications']:
        for med in analysis['medications']:
            output += f"\n‚úì {med['name']}\n"
            output += f"  Category: {med['info']['category']}\n"
            output += f"  Max Dose: {med['info']['max_dose']}\n"
            output += f"  Known Interactions: {med['info']['interactions']}\n"
    else:
        output += "\n‚ö†Ô∏è No medications from database detected. Manual review needed.\n"

    if analysis['dosages']:
        output += f"\nüìä Dosages Found: {', '.join([d[0]+d[1] for d in analysis['dosages']])}\n"

    if analysis['frequencies']:
        output += f"‚è∞ Frequencies Found: {', '.join([f[0]+' '+f[1] for f in analysis['frequencies']])}\n"

    output += f"\n{'='*60}\nü§ñ AI VERIFICATION ANALYSIS:\n{'='*60}\n"
    output += verification_report

    output += f"\n\n{'='*60}\n‚ö†Ô∏è  IMPORTANT DISCLAIMERS:\n{'='*60}\n"
    output += """
‚Ä¢ This is an AI-assisted analysis, NOT a substitute for professional medical advice
‚Ä¢ Always verify prescriptions with licensed healthcare providers
‚Ä¢ Do not make medication changes without consulting your doctor
‚Ä¢ In case of emergency, contact local emergency services immediately
‚Ä¢ Report any adverse drug reactions to your healthcare provider
"""

    # Translate if needed
    if lang_code != "en":
        output = translate_text(output, lang_code)
        extracted_text = translate_text(extracted_text, lang_code)

    return output, extracted_text, verification_report

def chatbot_interface(message, history, language):
    """Medical chatbot interface"""

    if not message:
        return history, history

    lang_code = LANGUAGE_MAP.get(language, "en")

    # Translate to English if needed
    if lang_code != "en":
        english_message = translate_text(message, "en")
    else:
        english_message = message

    # Generate response
    system_context = """You are a medical AI assistant. Provide helpful, accurate medical information
about medications, prescriptions, drug interactions, and general health queries. Always remind users
to consult healthcare professionals for medical decisions."""

    response = generate_response(english_message, max_length=512, system_context=system_context)

    # Add disclaimer
    response += "\n\n‚öïÔ∏è Always consult a healthcare professional for medical advice."

    # Translate response if needed
    if lang_code != "en":
        response = translate_text(response, lang_code)

    history.append((message, response))
    return history, history

def analyze_medical_image(image, language):
    """Analyze general medical images"""

    if image is None:
        return "Please upload an image."

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        # Generate image description
        result = image_analyzer(image)
        description = result[0]['generated_text']

        # Get AI analysis
        prompt = f"Based on this medical image description: '{description}', provide a brief medical observation and any relevant information. This is for educational purposes only."
        analysis = generate_response(prompt, max_length=400)

        output = f"""
üì∏ IMAGE DESCRIPTION:
{description}

üè• MEDICAL OBSERVATION:
{analysis}

‚ö†Ô∏è DISCLAIMER:
This is AI-generated analysis for educational purposes only.
For accurate diagnosis, please consult a qualified healthcare professional.
Do not use this for self-diagnosis or treatment decisions.
"""

        if lang_code != "en":
            output = translate_text(output, lang_code)

        return output
    except Exception as e:
        return f"Error analyzing image: {str(e)}"

# Create Gradio Interface
print("üé® Creating Gradio interface...")

with gr.Blocks(theme=gr.themes.Soft(), title="AI Medical Prescription Verification") as demo:

    gr.Markdown("""
    # üè• AI Medical Prescription Verification System
    ### Powered by IBM Granite 3.3 2B + Advanced OCR

    **Complete Medical AI Solution with:**
    - üíä Prescription OCR & Verification
    - üí¨ Medical Q&A Chatbot
    - üåê Multi-language Support (16+ Languages)
    - üì∏ Medical Image Analysis
    """)

    with gr.Tab("üíä Prescription Verification"):
        gr.Markdown("""
        ### Upload Prescription for AI-Powered Verification
        Upload a clear image of your prescription to extract text, identify medications, verify dosages, and check for potential interactions.
        """)

        with gr.Row():
            prescription_language = gr.Dropdown(
                choices=list(LANGUAGE_MAP.keys()),
                value="English",
                label="Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
                interactive=True
            )

        with gr.Row():
            with gr.Column(scale=1):
                prescription_image = gr.Image(
                    label="üì§ Upload Prescription Image",
                    type="pil",
                    height=400
                )
                verify_btn = gr.Button("üîç Verify Prescription", variant="primary", size="lg")

                gr.Markdown("""
                **Tips for best results:**
                - Use clear, well-lit images
                - Ensure text is readable
                - Avoid shadows and glare
                - Capture entire prescription
                """)

            with gr.Column(scale=2):
                verification_output = gr.Textbox(
                    label="üìã Verification Report",
                    lines=25,
                    placeholder="Verification results will appear here...",
                    max_lines=30
                )

        with gr.Row():
            with gr.Column():
                extracted_text_output = gr.Textbox(
                    label="üìÑ Extracted Text (Raw OCR)",
                    lines=5,
                    placeholder="Extracted text will appear here..."
                )
            with gr.Column():
                ai_analysis_output = gr.Textbox(
                    label="ü§ñ AI Analysis Summary",
                    lines=5,
                    placeholder="AI analysis will appear here..."
                )

        verify_btn.click(
            verify_prescription,
            inputs=[prescription_image, prescription_language],
            outputs=[verification_output, extracted_text_output, ai_analysis_output]
        )

    with gr.Tab("üí¨ Medical Chatbot"):
        gr.Markdown("""
        ### Ask Medical Questions
        Get AI-powered answers about medications, health conditions, drug interactions, and general medical information.
        """)

        with gr.Row():
            chat_language = gr.Dropdown(
                choices=list(LANGUAGE_MAP.keys()),
                value="English",
                label="Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
                interactive=True
            )

        chatbot = gr.Chatbot(
            label="Medical AI Assistant",
            height=500,
            bubble_full_width=False,
            avatar_images=("üë§", "ü§ñ")
        )

        with gr.Row():
            msg = gr.Textbox(
                placeholder="Ask about medications, dosages, interactions, side effects... / ‡§¶‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡•á‡§Ç...",
                label="Your Question",
                scale=4
            )
            send_btn = gr.Button("Send üì§", scale=1, variant="primary")

        with gr.Row():
            clear = gr.Button("Clear üóëÔ∏è")

            gr.Examples(
                examples=[
                    "What are the side effects of paracetamol?",
                    "Can I take ibuprofen with aspirin?",
                    "What is the maximum safe dose of metformin?",
                    "‡§™‡•á‡§∞‡§æ‡§∏‡§ø‡§ü‡§æ‡§Æ‡•ã‡§≤ ‡§ï‡•á ‡§¶‡•Å‡§∑‡•ç‡§™‡•ç‡§∞‡§≠‡§æ‡§µ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡§Ç?",
                    "How should I store antibiotics?"
                ],
                inputs=msg
            )

        chat_history = gr.State([])

        send_btn.click(
            chatbot_interface,
            inputs=[msg, chat_history, chat_language],
            outputs=[chatbot, chat_history]
        ).then(lambda: "", outputs=[msg])

        msg.submit(
            chatbot_interface,
            inputs=[msg, chat_history, chat_language],
            outputs=[chatbot, chat_history]
        ).then(lambda: "", outputs=[msg])

        clear.click(lambda: ([], []), outputs=[chatbot, chat_history])

    with gr.Tab("üì∏ Medical Image Analysis"):
        gr.Markdown("""
        ### Analyze Medical Images
        Upload X-rays, scans, or other medical images for AI-powered description and observation.
        """)

        with gr.Row():
            image_language = gr.Dropdown(
                choices=list(LANGUAGE_MAP.keys()),
                value="English",
                label="Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
                interactive=True
            )

        with gr.Row():
            with gr.Column():
                medical_image = gr.Image(
                    label="üì§ Upload Medical Image",
                    type="pil",
                    height=400
                )
                analyze_btn = gr.Button("üîç Analyze Image", variant="primary", size="lg")

            with gr.Column():
                image_analysis_output = gr.Textbox(
                    label="üìä Analysis Result",
                    lines=20,
                    placeholder="Image analysis will appear here..."
                )

        analyze_btn.click(
            analyze_medical_image,
            inputs=[medical_image, image_language],
            outputs=[image_analysis_output]
        )

    with gr.Tab("‚ÑπÔ∏è About & Help"):
        gr.Markdown("""
        ## üìö About This System

        ### üéØ Features

        **1. üíä Prescription Verification**
        - Advanced OCR text extraction from prescription images
        - Automatic medication identification
        - Dosage verification against safe limits
        - Drug interaction checking
        - Comprehensive safety analysis

        **2. üí¨ Medical Chatbot**
        - Ask questions about medications and health
        - Get information about drug interactions
        - Learn about proper dosages and administration
        - Understand side effects and precautions

        **3. üåê Multi-language Support**
        - **Indian Languages**: Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, Punjabi, Urdu
        - **International**: English, Spanish, French, German, Chinese, Arabic

        **4. üì∏ Medical Image Analysis**
        - AI-powered image description
        - Medical observation generation
        - Educational insights

        ### üõ°Ô∏è Safety Features

        ‚úì Database of common medications with safety information
        ‚úì Drug interaction warnings
        ‚úì Dosage limit verification
        ‚úì Clear medical disclaimers
        ‚úì Emphasis on professional consultation

        ### ‚ö†Ô∏è CRITICAL DISCLAIMERS

        **THIS SYSTEM IS FOR EDUCATIONAL AND INFORMATIONAL PURPOSES ONLY**

        - ‚ùå NOT a substitute for professional medical advice
        - ‚ùå NOT for diagnosis or treatment decisions
        - ‚ùå NOT validated for clinical use
        - ‚ùå NOT a replacement for pharmacist verification

        **ALWAYS:**
        - ‚úÖ Consult licensed healthcare professionals
        - ‚úÖ Verify prescriptions with your pharmacist
        - ‚úÖ Follow your doctor's instructions
        - ‚úÖ Report adverse reactions immediately
        - ‚úÖ Call emergency services for urgent medical issues

        ### üî¨ Technology Stack

        - **AI Model**: IBM Granite 3.3 2B Instruct
        - **OCR**: Tesseract + EasyOCR
        - **Image Analysis**: BLIP Captioning
        - **Translation**: Google Translate
        - **Interface**: Gradio
        - **Framework**: PyTorch + Transformers

        ### üìû Emergency Contacts (India)

        - Emergency: **112**
        - Ambulance: **102**
        - Poison Control: **1066**

        ### üìñ How to Use

        **For Prescription Verification:**
        1. Select your preferred language
        2. Upload a clear photo of your prescription
        3. Click "Verify Prescription"
        4. Review the detailed analysis report
        5. Consult your pharmacist or doctor for confirmation

        **For Medical Chatbot:**
        1. Select your preferred language
        2. Type your medical question
        3. Review the AI-generated response
        4. Ask follow-up questions as needed

        **For Image Analysis:**
        1. Select your preferred language
        2. Upload your medical image
        3. Click "Analyze Image"
        4. Review the AI observations

        ---

        ### üë®‚Äç‚öïÔ∏è Developed for Healthcare Education

        This system demonstrates the potential of AI in healthcare while emphasizing
        the irreplaceable role of human medical professionals. Use responsibly.

        **Version**: 1.0.0
        **Last Updated**: 2024
        """)

print("‚úÖ System initialization complete!")
print("üöÄ Launching AI Medical Prescription Verification System...")
print("üîó A shareable link will be generated below...")

# Launch the application
demo.launch(
    share=True,
    debug=False,
    show_error=True
)

# AI Medical Prescription Verification System - FIXED VERSION
# Features: Prescription Verification, Medical Chatbot, Language Translation, Image Analysis
# Powered by IBM Granite 3.3 2B + Advanced OCR
# Ready to run in Google Colab

# Fix numpy compatibility first
!pip uninstall -y numpy -q
!pip install numpy==2.0.0 -q

# Install required packages with specific versions to avoid conflicts
!pip install -q gradio==4.44.0
!pip install -q transformers torch pillow huggingface_hub accelerate
!pip install -q deep-translator pytesseract easyocr opencv-python-headless

# Install Tesseract OCR
!apt-get install -q tesseract-ocr > /dev/null 2>&1
!apt-get install -q tesseract-ocr-hin tesseract-ocr-tam tesseract-ocr-tel > /dev/null 2>&1

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from PIL import Image
from deep_translator import GoogleTranslator
import pytesseract
import easyocr
import cv2
import numpy as np
import warnings
import re
from datetime import datetime
warnings.filterwarnings('ignore')

print("üîß Initializing AI Medical Prescription Verification System...")

# Initialize the IBM Granite model
model_name = "ibm-granite/granite-3.0-2b-instruct"
print(f"üì• Loading {model_name}...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto",
    low_cpu_mem_usage=True
)

# Initialize EasyOCR reader
print("üîß Loading OCR engines...")
reader = easyocr.Reader(['en', 'hi'], gpu=torch.cuda.is_available())

# Initialize image analysis model
print("üîß Loading image analysis model...")
image_analyzer = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")

# Language mapping with Indian languages
LANGUAGE_MAP = {
    "English": "en",
    "Hindi": "hi",
    "Tamil": "ta",
    "Telugu": "te",
    "Bengali": "bn",
    "Marathi": "mr",
    "Gujarati": "gu",
    "Kannada": "kn",
    "Malayalam": "ml",
    "Punjabi": "pa",
    "Urdu": "ur",
    "Spanish": "es",
    "French": "fr",
    "German": "de",
    "Chinese (Simplified)": "zh-CN",
    "Arabic": "ar"
}

# Common medication database
MEDICATION_DATABASE = {
    "paracetamol": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "acetaminophen": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "ibuprofen": {"max_dose": "3200mg/day", "category": "NSAID", "interactions": "aspirin, blood thinners"},
    "amoxicillin": {"max_dose": "3000mg/day", "category": "Antibiotic", "interactions": "methotrexate"},
    "azithromycin": {"max_dose": "500mg/day", "category": "Antibiotic", "interactions": "warfarin"},
    "metformin": {"max_dose": "2550mg/day", "category": "Antidiabetic", "interactions": "alcohol, contrast dye"},
    "aspirin": {"max_dose": "4000mg/day", "category": "Analgesic/Antiplatelet", "interactions": "ibuprofen, warfarin"},
    "omeprazole": {"max_dose": "40mg/day", "category": "PPI", "interactions": "clopidogrel"},
    "atorvastatin": {"max_dose": "80mg/day", "category": "Statin", "interactions": "grapefruit juice"},
    "lisinopril": {"max_dose": "80mg/day", "category": "ACE Inhibitor", "interactions": "potassium supplements"},
    "amlodipine": {"max_dose": "10mg/day", "category": "Calcium Channel Blocker", "interactions": "grapefruit juice"},
    "levothyroxine": {"max_dose": "300mcg/day", "category": "Thyroid Hormone", "interactions": "iron, calcium"},
    "gabapentin": {"max_dose": "3600mg/day", "category": "Anticonvulsant", "interactions": "antacids"},
    "prednisone": {"max_dose": "60mg/day", "category": "Corticosteroid", "interactions": "NSAIDs"},
    "ciprofloxacin": {"max_dose": "1500mg/day", "category": "Antibiotic", "interactions": "dairy products"},
}

def generate_response(prompt, max_length=512, system_context=None):
    """Generate response using IBM Granite model"""

    if system_context is None:
        system_context = """You are an expert medical AI assistant specializing in prescription verification and medication safety.
Provide accurate, detailed medical information while always emphasizing the importance of consulting healthcare professionals."""

    full_prompt = f"{system_context}\n\nUser: {prompt}\nAssistant:"

    inputs = tokenizer(full_prompt, return_tensors="pt", truncation=True, max_length=2048)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_length,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    if "Assistant:" in response:
        response = response.split("Assistant:")[-1].strip()

    return response

def translate_text(text, target_lang):
    """Translate text to target language using deep-translator"""
    try:
        if target_lang == "en" or not text or len(text.strip()) == 0:
            return text

        # Split into chunks if text is too long
        max_chunk_size = 4500
        if len(text) > max_chunk_size:
            chunks = [text[i:i+max_chunk_size] for i in range(0, len(text), max_chunk_size)]
            translated_chunks = []
            for chunk in chunks:
                translator = GoogleTranslator(source='auto', target=target_lang)
                translated = translator.translate(chunk)
                translated_chunks.append(translated)
            return " ".join(translated_chunks)
        else:
            translator = GoogleTranslator(source='auto', target=target_lang)
            return translator.translate(text)
    except Exception as e:
        print(f"Translation error: {e}")
        return text  # Return original if translation fails

def extract_text_from_image(image):
    """Extract text from prescription image using OCR"""
    try:
        # Convert PIL image to numpy array
        img_array = np.array(image)

        # Use EasyOCR
        results = reader.readtext(img_array)
        extracted_text = " ".join([result[1] for result in results])

        # Also try Tesseract as backup
        tesseract_text = pytesseract.image_to_string(image)

        # Combine both results
        combined_text = extracted_text + " " + tesseract_text

        return combined_text.strip()
    except Exception as e:
        return f"Error extracting text: {str(e)}"

def analyze_prescription(text):
    """Analyze prescription text for medications and dosages"""

    medications_found = []

    # Search for known medications
    text_lower = text.lower()
    for med_name, med_info in MEDICATION_DATABASE.items():
        if med_name in text_lower:
            medications_found.append({
                "name": med_name.title(),
                "info": med_info
            })

    # Extract dosage patterns
    dosage_pattern = r'\d+\s*(mg|ml|g|mcg|units?)'
    dosages = re.findall(dosage_pattern, text_lower)

    # Extract frequency patterns
    frequency_pattern = r'(once|twice|thrice|\d+x?)\s*(daily|per day|/day|a day)'
    frequencies = re.findall(frequency_pattern, text_lower)

    return {
        "medications": medications_found,
        "dosages": dosages,
        "frequencies": frequencies,
        "raw_text": text
    }

def verify_prescription(image, language):
    """Complete prescription verification pipeline"""

    if image is None:
        return "‚ùå Please upload a prescription image.", "", ""

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        # Step 1: Extract text from image
        extracted_text = extract_text_from_image(image)

        if not extracted_text or len(extracted_text) < 10:
            error_msg = "‚ö†Ô∏è Could not extract sufficient text from the image. Please ensure:\n- Image is clear and well-lit\n- Text is readable\n- Prescription is in focus"
            return translate_text(error_msg, lang_code), "", ""

        # Step 2: Analyze prescription
        analysis = analyze_prescription(extracted_text)

        # Step 3: Generate verification report
        verification_prompt = f"""Analyze this prescription text and provide a detailed verification report:

Extracted Text: {extracted_text[:500]}

Medications Found: {[m['name'] for m in analysis['medications']]}

Please provide:
1. List of identified medications
2. Dosage verification (safe/unsafe ranges)
3. Potential drug interactions
4. Important warnings or precautions
5. Recommendations

Format the response clearly with sections."""

        verification_report = generate_response(verification_prompt, max_length=800)

        # Step 4: Create structured output
        output = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          PRESCRIPTION VERIFICATION REPORT                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìÖ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{'='*60}
üìã EXTRACTED TEXT:
{'='*60}
{extracted_text}

{'='*60}
üíä IDENTIFIED MEDICATIONS:
{'='*60}
"""

        if analysis['medications']:
            for med in analysis['medications']:
                output += f"\n‚úì {med['name']}\n"
                output += f"  Category: {med['info']['category']}\n"
                output += f"  Max Dose: {med['info']['max_dose']}\n"
                output += f"  Known Interactions: {med['info']['interactions']}\n"
        else:
            output += "\n‚ö†Ô∏è No medications from database detected. Manual review needed.\n"

        if analysis['dosages']:
            output += f"\nüìä Dosages Found: {', '.join([d[0]+d[1] for d in analysis['dosages']])}\n"

        if analysis['frequencies']:
            output += f"‚è∞ Frequencies Found: {', '.join([f[0]+' '+f[1] for f in analysis['frequencies']])}\n"

        output += f"\n{'='*60}\nü§ñ AI VERIFICATION ANALYSIS:\n{'='*60}\n"
        output += verification_report

        output += f"\n\n{'='*60}\n‚ö†Ô∏è  IMPORTANT DISCLAIMERS:\n{'='*60}\n"
        output += """
‚Ä¢ This is an AI-assisted analysis, NOT a substitute for professional medical advice
‚Ä¢ Always verify prescriptions with licensed healthcare providers
‚Ä¢ Do not make medication changes without consulting your doctor
‚Ä¢ In case of emergency, contact local emergency services immediately
‚Ä¢ Report any adverse drug reactions to your healthcare provider
"""

        # Translate if needed
        if lang_code != "en":
            output = translate_text(output, lang_code)
            extracted_text_display = translate_text(extracted_text[:300], lang_code)
        else:
            extracted_text_display = extracted_text[:300]

        return output, extracted_text_display, verification_report

    except Exception as e:
        error_msg = f"Error processing prescription: {str(e)}"
        return error_msg, "", ""

def chatbot_interface(message, history, language):
    """Medical chatbot interface"""

    if not message:
        return history, history

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        # Translate to English if needed
        if lang_code != "en":
            english_message = translate_text(message, "en")
        else:
            english_message = message

        # Generate response
        system_context = """You are a medical AI assistant. Provide helpful, accurate medical information
about medications, prescriptions, drug interactions, and general health queries. Always remind users
to consult healthcare professionals for medical decisions."""

        response = generate_response(english_message, max_length=512, system_context=system_context)

        # Add disclaimer
        response += "\n\n‚öïÔ∏è Always consult a healthcare professional for medical advice."

        # Translate response if needed
        if lang_code != "en":
            response = translate_text(response, lang_code)

        history.append((message, response))
        return history, history

    except Exception as e:
        error_response = f"Error: {str(e)}"
        history.append((message, error_response))
        return history, history

def analyze_medical_image(image, language):
    """Analyze general medical images"""

    if image is None:
        return "Please upload an image."

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        # Generate image description
        result = image_analyzer(image)
        description = result[0]['generated_text']

        # Get AI analysis
        prompt = f"Based on this medical image description: '{description}', provide a brief medical observation and any relevant information. This is for educational purposes only."
        analysis = generate_response(prompt, max_length=400)

        output = f"""
üì∏ IMAGE DESCRIPTION:
{description}

üè• MEDICAL OBSERVATION:
{analysis}

‚ö†Ô∏è DISCLAIMER:
This is AI-generated analysis for educational purposes only.
For accurate diagnosis, please consult a qualified healthcare professional.
Do not use this for self-diagnosis or treatment decisions.
"""

        if lang_code != "en":
            output = translate_text(output, lang_code)

        return output
    except Exception as e:
        return f"Error analyzing image: {str(e)}"

# Create Gradio Interface
print("üé® Creating Gradio interface...")

with gr.Blocks(theme=gr.themes.Soft(), title="AI Medical Prescription Verification") as demo:

    gr.Markdown("""
    # üè• AI Medical Prescription Verification System
    ### Powered by IBM Granite 3.3 2B + Advanced OCR

    **Complete Medical AI Solution with:**
    - üíä Prescription OCR & Verification
    - üí¨ Medical Q&A Chatbot
    - üåê Multi-language Support (16+ Languages)
    - üì∏ Medical Image Analysis
    """)

    with gr.Tab("üíä Prescription Verification"):
        gr.Markdown("""
        ### Upload Prescription for AI-Powered Verification
        Upload a clear image of your prescription to extract text, identify medications, verify dosages, and check for potential interactions.
        """)

        with gr.Row():
            prescription_language = gr.Dropdown(
                choices=list(LANGUAGE_MAP.keys()),
                value="English",
                label="Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
                interactive=True
            )

        with gr.Row():
            with gr.Column(scale=1):
                prescription_image = gr.Image(
                    label="üì§ Upload Prescription Image",
                    type="pil",
                    height=400
                )
                verify_btn = gr.Button("üîç Verify Prescription", variant="primary", size="lg")

                gr.Markdown("""
                **Tips for best results:**
                - Use clear, well-lit images
                - Ensure text is readable
                - Avoid shadows and glare
                - Capture entire prescription
                """)

            with gr.Column(scale=2):
                verification_output = gr.Textbox(
                    label="üìã Verification Report",
                    lines=25,
                    placeholder="Verification results will appear here...",
                    max_lines=30
                )

        with gr.Row():
            with gr.Column():
                extracted_text_output = gr.Textbox(
                    label="üìÑ Extracted Text (Raw OCR)",
                    lines=5,
                    placeholder="Extracted text will appear here..."
                )
            with gr.Column():
                ai_analysis_output = gr.Textbox(
                    label="ü§ñ AI Analysis Summary",
                    lines=5,
                    placeholder="AI analysis will appear here..."
                )

        verify_btn.click(
            verify_prescription,
            inputs=[prescription_image, prescription_language],
            outputs=[verification_output, extracted_text_output, ai_analysis_output]
        )

    with gr.Tab("üí¨ Medical Chatbot"):
        gr.Markdown("""
        ### Ask Medical Questions
        Get AI-powered answers about medications, health conditions, drug interactions, and general medical information.
        """)

        with gr.Row():
            chat_language = gr.Dropdown(
                choices=list(LANGUAGE_MAP.keys()),
                value="English",
                label="Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
                interactive=True
            )

        chatbot = gr.Chatbot(
            label="Medical AI Assistant",
            height=500,
            bubble_full_width=False,
            avatar_images=("üë§", "ü§ñ")
        )

        with gr.Row():
            msg = gr.Textbox(
                placeholder="Ask about medications, dosages, interactions, side effects...",
                label="Your Question",
                scale=4
            )
            send_btn = gr.Button("Send üì§", scale=1, variant="primary")

        with gr.Row():
            clear = gr.Button("Clear üóëÔ∏è")

            gr.Examples(
                examples=[
                    "What are the side effects of paracetamol?",
                    "Can I take ibuprofen with aspirin?",
                    "What is the maximum safe dose of metformin?",
                    "How should I store antibiotics?"
                ],
                inputs=msg
            )

        chat_history = gr.State([])

        send_btn.click(
            chatbot_interface,
            inputs=[msg, chat_history, chat_language],
            outputs=[chatbot, chat_history]
        ).then(lambda: "", outputs=[msg])

        msg.submit(
            chatbot_interface,
            inputs=[msg, chat_history, chat_language],
            outputs=[chatbot, chat_history]
        ).then(lambda: "", outputs=[msg])

        clear.click(lambda: ([], []), outputs=[chatbot, chat_history])

    with gr.Tab("üì∏ Medical Image Analysis"):
        gr.Markdown("""
        ### Analyze Medical Images
        Upload X-rays, scans, or other medical images for AI-powered description and observation.
        """)

        with gr.Row():
            image_language = gr.Dropdown(
                choices=list(LANGUAGE_MAP.keys()),
                value="English",
                label="Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
                interactive=True
            )

        with gr.Row():
            with gr.Column():
                medical_image = gr.Image(
                    label="üì§ Upload Medical Image",
                    type="pil",
                    height=400
                )
                analyze_btn = gr.Button("üîç Analyze Image", variant="primary", size="lg")

            with gr.Column():
                image_analysis_output = gr.Textbox(
                    label="üìä Analysis Result",
                    lines=20,
                    placeholder="Image analysis will appear here..."
                )

        analyze_btn.click(
            analyze_medical_image,
            inputs=[medical_image, image_language],
            outputs=[image_analysis_output]
        )

    with gr.Tab("‚ÑπÔ∏è About"):
        gr.Markdown("""
        ## üìö About This System

        ### üéØ Features

        **1. üíä Prescription Verification**
        - Advanced OCR text extraction
        - Automatic medication identification
        - Dosage verification
        - Drug interaction checking

        **2. üí¨ Medical Chatbot**
        - Ask questions about medications
        - Get information about drug interactions
        - Learn about proper dosages

        **3. üåê Multi-language Support**
        - Indian Languages: Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, Punjabi, Urdu
        - International: English, Spanish, French, German, Chinese, Arabic

        **4. üì∏ Medical Image Analysis**
        - AI-powered image description
        - Medical observation generation

        ### ‚ö†Ô∏è CRITICAL DISCLAIMERS

        **THIS SYSTEM IS FOR EDUCATIONAL PURPOSES ONLY**

        - ‚ùå NOT a substitute for professional medical advice
        - ‚ùå NOT for diagnosis or treatment decisions
        - ‚ùå NOT validated for clinical use

        **ALWAYS:**
        - ‚úÖ Consult licensed healthcare professionals
        - ‚úÖ Verify prescriptions with your pharmacist
        - ‚úÖ Follow your doctor's instructions

        ### üî¨ Technology Stack

        - **AI Model**: IBM Granite 3.3 2B
        - **OCR**: Tesseract + EasyOCR
        - **Translation**: Deep Translator
        - **Interface**: Gradio

        ### üìû Emergency (India): 112

        ---
        **Developed for Healthcare Education**
        """)

print("‚úÖ System initialization complete!")
print("üöÄ Launching AI Medical Prescription Verification System...")

# Launch the application
demo.launch(share=True, debug=False)

# AI Medical Prescription Verification System - ERROR-FREE VERSION
# Optimized for Google Colab - Single Cell Execution
# All dependency conflicts resolved

import sys
import subprocess

# Clean installation function
def install_packages():
    """Install packages with proper dependency management"""

    # Step 1: Upgrade pip
    subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "pip", "-q"])

    # Step 2: Install core packages
    packages = [
        "torch",
        "transformers",
        "accelerate",
        "huggingface_hub",
        "pillow",
        "opencv-python-headless",
        "pytesseract",
        "deep-translator",
        "gradio",
    ]

    for package in packages:
        print(f"Installing {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package, "-q"])

    # Step 3: Install EasyOCR separately (it has specific requirements)
    print("Installing EasyOCR...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "easyocr", "-q"])

    print("‚úÖ All packages installed successfully!")

# Install everything
print("üì¶ Installing required packages...")
install_packages()

# Install Tesseract OCR system packages
print("üì• Installing Tesseract OCR...")
import os
os.system("apt-get install -y tesseract-ocr > /dev/null 2>&1")
os.system("apt-get install -y tesseract-ocr-hin tesseract-ocr-tam tesseract-ocr-tel > /dev/null 2>&1")

# Now import everything
print("üìö Importing libraries...")
import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from PIL import Image
from deep_translator import GoogleTranslator
import pytesseract
import easyocr
import cv2
import numpy as np
import warnings
import re
from datetime import datetime
warnings.filterwarnings('ignore')

print("üîß Initializing AI Medical Prescription Verification System...")

# Initialize the IBM Granite model
model_name = "ibm-granite/granite-3.0-2b-instruct"
print(f"üì• Loading {model_name}...")

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        device_map="auto",
        low_cpu_mem_usage=True,
        trust_remote_code=True
    )
    print("‚úÖ IBM Granite model loaded successfully!")
except Exception as e:
    print(f"‚ö†Ô∏è Error loading model: {e}")
    print("Attempting alternative loading method...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")

# Initialize EasyOCR reader
print("üîß Loading OCR engines...")
try:
    reader = easyocr.Reader(['en', 'hi'], gpu=torch.cuda.is_available(), verbose=False)
    print("‚úÖ OCR engines loaded!")
except Exception as e:
    print(f"‚ö†Ô∏è OCR initialization: {e}")
    reader = easyocr.Reader(['en'], gpu=False, verbose=False)

# Initialize image analysis model
print("üîß Loading image analysis model...")
try:
    image_analyzer = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
    print("‚úÖ Image analyzer loaded!")
except Exception as e:
    print(f"‚ö†Ô∏è Image analyzer: {e}")
    image_analyzer = None

# Language mapping with Indian languages
LANGUAGE_MAP = {
    "English": "en",
    "Hindi": "hi",
    "Tamil": "ta",
    "Telugu": "te",
    "Bengali": "bn",
    "Marathi": "mr",
    "Gujarati": "gu",
    "Kannada": "kn",
    "Malayalam": "ml",
    "Punjabi": "pa",
    "Urdu": "ur",
    "Spanish": "es",
    "French": "fr",
    "German": "de",
    "Chinese": "zh-CN",
    "Arabic": "ar"
}

# Medication database
MEDICATION_DATABASE = {
    "paracetamol": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "acetaminophen": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "ibuprofen": {"max_dose": "3200mg/day", "category": "NSAID", "interactions": "aspirin, blood thinners"},
    "amoxicillin": {"max_dose": "3000mg/day", "category": "Antibiotic", "interactions": "methotrexate"},
    "azithromycin": {"max_dose": "500mg/day", "category": "Antibiotic", "interactions": "warfarin"},
    "metformin": {"max_dose": "2550mg/day", "category": "Antidiabetic", "interactions": "alcohol, contrast dye"},
    "aspirin": {"max_dose": "4000mg/day", "category": "Analgesic/Antiplatelet", "interactions": "ibuprofen, warfarin"},
    "omeprazole": {"max_dose": "40mg/day", "category": "PPI", "interactions": "clopidogrel"},
    "atorvastatin": {"max_dose": "80mg/day", "category": "Statin", "interactions": "grapefruit juice"},
    "lisinopril": {"max_dose": "80mg/day", "category": "ACE Inhibitor", "interactions": "potassium supplements"},
    "amlodipine": {"max_dose": "10mg/day", "category": "Calcium Channel Blocker", "interactions": "grapefruit juice"},
    "levothyroxine": {"max_dose": "300mcg/day", "category": "Thyroid Hormone", "interactions": "iron, calcium"},
    "gabapentin": {"max_dose": "3600mg/day", "category": "Anticonvulsant", "interactions": "antacids"},
    "prednisone": {"max_dose": "60mg/day", "category": "Corticosteroid", "interactions": "NSAIDs"},
    "ciprofloxacin": {"max_dose": "1500mg/day", "category": "Antibiotic", "interactions": "dairy products"},
    "dolo": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "crocin": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "combiflam": {"max_dose": "3200mg/day", "category": "NSAID", "interactions": "aspirin"},
}

def generate_response(prompt, max_length=512, system_context=None):
    """Generate response using IBM Granite model"""

    try:
        if system_context is None:
            system_context = """You are an expert medical AI assistant specializing in prescription verification and medication safety.
Provide accurate, detailed medical information while always emphasizing the importance of consulting healthcare professionals."""

        full_prompt = f"{system_context}\n\nUser: {prompt}\nAssistant:"

        inputs = tokenizer(full_prompt, return_tensors="pt", truncation=True, max_length=2048)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_length,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        if "Assistant:" in response:
            response = response.split("Assistant:")[-1].strip()

        return response
    except Exception as e:
        return f"Error generating response: {str(e)}"

def translate_text(text, target_lang):
    """Translate text to target language"""
    try:
        if target_lang == "en" or not text or len(text.strip()) == 0:
            return text

        # Handle long text
        max_chunk = 4500
        if len(text) > max_chunk:
            chunks = [text[i:i+max_chunk] for i in range(0, len(text), max_chunk)]
            results = []
            for chunk in chunks:
                try:
                    translator = GoogleTranslator(source='auto', target=target_lang)
                    results.append(translator.translate(chunk))
                except:
                    results.append(chunk)
            return " ".join(results)
        else:
            translator = GoogleTranslator(source='auto', target=target_lang)
            return translator.translate(text)
    except Exception as e:
        return text

def extract_text_from_image(image):
    """Extract text from prescription image using OCR"""
    try:
        img_array = np.array(image)

        # Method 1: EasyOCR
        extracted_text = ""
        try:
            results = reader.readtext(img_array)
            extracted_text = " ".join([result[1] for result in results])
        except:
            pass

        # Method 2: Tesseract
        tesseract_text = ""
        try:
            tesseract_text = pytesseract.image_to_string(image)
        except:
            pass

        # Combine results
        combined = (extracted_text + " " + tesseract_text).strip()
        return combined if combined else "Could not extract text from image."

    except Exception as e:
        return f"Error: {str(e)}"

def analyze_prescription(text):
    """Analyze prescription text"""

    medications_found = []
    text_lower = text.lower()

    for med_name, med_info in MEDICATION_DATABASE.items():
        if med_name in text_lower:
            medications_found.append({
                "name": med_name.title(),
                "info": med_info
            })

    dosage_pattern = r'\d+\s*(mg|ml|g|mcg|units?)'
    dosages = re.findall(dosage_pattern, text_lower)

    frequency_pattern = r'(once|twice|thrice|\d+x?)\s*(daily|per day|/day|a day)'
    frequencies = re.findall(frequency_pattern, text_lower)

    return {
        "medications": medications_found,
        "dosages": dosages,
        "frequencies": frequencies,
        "raw_text": text
    }

def verify_prescription(image, language):
    """Complete prescription verification"""

    if image is None:
        return "‚ùå Please upload a prescription image.", "", ""

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        # Extract text
        extracted_text = extract_text_from_image(image)

        if len(extracted_text) < 10:
            msg = "‚ö†Ô∏è Could not extract text. Ensure image is clear and well-lit."
            return translate_text(msg, lang_code), "", ""

        # Analyze
        analysis = analyze_prescription(extracted_text)

        # Generate AI report
        prompt = f"""Analyze this prescription:

Text: {extracted_text[:500]}
Medications: {[m['name'] for m in analysis['medications']]}

Provide:
1. Identified medications
2. Dosage safety check
3. Drug interactions
4. Warnings
5. Recommendations"""

        ai_report = generate_response(prompt, max_length=800)

        # Create report
        output = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          PRESCRIPTION VERIFICATION REPORT                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{'='*60}
üìã EXTRACTED TEXT:
{'='*60}
{extracted_text}

{'='*60}
üíä IDENTIFIED MEDICATIONS:
{'='*60}
"""

        if analysis['medications']:
            for med in analysis['medications']:
                output += f"\n‚úì {med['name']}\n"
                output += f"  Category: {med['info']['category']}\n"
                output += f"  Max Dose: {med['info']['max_dose']}\n"
                output += f"  Interactions: {med['info']['interactions']}\n"
        else:
            output += "\n‚ö†Ô∏è No medications from database detected.\n"

        if analysis['dosages']:
            output += f"\nüìä Dosages: {', '.join([d[0]+d[1] for d in analysis['dosages']])}\n"

        if analysis['frequencies']:
            output += f"‚è∞ Frequency: {', '.join([f[0]+' '+f[1] for f in analysis['frequencies']])}\n"

        output += f"\n{'='*60}\nü§ñ AI ANALYSIS:\n{'='*60}\n"
        output += ai_report

        output += f"\n\n{'='*60}\n‚ö†Ô∏è DISCLAIMERS:\n{'='*60}\n"
        output += """
‚Ä¢ AI-assisted analysis only - NOT medical advice
‚Ä¢ Verify with licensed healthcare provider
‚Ä¢ Do not change medications without doctor consultation
‚Ä¢ Emergency: Call 112 (India)
"""

        if lang_code != "en":
            output = translate_text(output, lang_code)

        return output, extracted_text[:300], ai_report[:300]

    except Exception as e:
        return f"Error: {str(e)}", "", ""

def chatbot_interface(message, history, language):
    """Medical chatbot"""

    if not message:
        return history, history

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        # Translate to English
        english_msg = translate_text(message, "en") if lang_code != "en" else message

        # Generate response
        context = """You are a medical AI assistant. Provide helpful medical information
about medications and health. Always advise consulting healthcare professionals."""

        response = generate_response(english_msg, max_length=512, system_context=context)
        response += "\n\n‚öïÔ∏è Consult a healthcare professional for medical advice."

        # Translate back
        if lang_code != "en":
            response = translate_text(response, lang_code)

        history.append((message, response))
        return history, history

    except Exception as e:
        history.append((message, f"Error: {str(e)}"))
        return history, history

def analyze_medical_image(image, language):
    """Analyze medical images"""

    if image is None:
        return "Please upload an image."

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        if image_analyzer:
            result = image_analyzer(image)
            description = result[0]['generated_text']
        else:
            description = "Image analyzer not available."

        prompt = f"Medical image shows: '{description}'. Provide educational observation."
        analysis = generate_response(prompt, max_length=400)

        output = f"""
üì∏ IMAGE DESCRIPTION:
{description}

üè• MEDICAL OBSERVATION:
{analysis}

‚ö†Ô∏è DISCLAIMER:
Educational purposes only. Consult healthcare professional for diagnosis.
"""

        if lang_code != "en":
            output = translate_text(output, lang_code)

        return output
    except Exception as e:
        return f"Error: {str(e)}"

# Create Gradio Interface
print("üé® Creating interface...")

with gr.Blocks(theme=gr.themes.Soft(), title="AI Medical Prescription Verification") as demo:

    gr.Markdown("""
    # üè• AI Medical Prescription Verification System
    ### IBM Granite 3.3 2B + Advanced OCR

    **Features:** Prescription Verification ‚Ä¢ Medical Chatbot ‚Ä¢ Multi-language ‚Ä¢ Image Analysis
    """)

    with gr.Tab("üíä Prescription Verification"):
        gr.Markdown("### AI-Powered Prescription Analysis")

        prescription_language = gr.Dropdown(
            choices=list(LANGUAGE_MAP.keys()),
            value="English",
            label="Language / ‡§≠‡§æ‡§∑‡§æ"
        )

        with gr.Row():
            with gr.Column(scale=1):
                prescription_image = gr.Image(label="üì§ Upload Prescription", type="pil", height=400)
                verify_btn = gr.Button("üîç Verify Prescription", variant="primary", size="lg")

            with gr.Column(scale=2):
                verification_output = gr.Textbox(label="üìã Report", lines=25)

        with gr.Row():
            extracted_text_output = gr.Textbox(label="üìÑ Extracted Text", lines=5)
            ai_analysis_output = gr.Textbox(label="ü§ñ AI Summary", lines=5)

        verify_btn.click(
            verify_prescription,
            inputs=[prescription_image, prescription_language],
            outputs=[verification_output, extracted_text_output, ai_analysis_output]
        )

    with gr.Tab("üí¨ Medical Chatbot"):
        gr.Markdown("### Ask Medical Questions")

        chat_language = gr.Dropdown(
            choices=list(LANGUAGE_MAP.keys()),
            value="English",
            label="Language / ‡§≠‡§æ‡§∑‡§æ"
        )

        chatbot = gr.Chatbot(label="Medical AI", height=500, avatar_images=("üë§", "ü§ñ"))

        with gr.Row():
            msg = gr.Textbox(label="Your Question", scale=4, placeholder="Ask about medications...")
            send_btn = gr.Button("Send üì§", scale=1, variant="primary")

        clear = gr.Button("Clear üóëÔ∏è")

        gr.Examples(
            examples=[
                "What are paracetamol side effects?",
                "Can I take ibuprofen with aspirin?",
                "Maximum dose of metformin?"
            ],
            inputs=msg
        )

        chat_history = gr.State([])

        send_btn.click(chatbot_interface, [msg, chat_history, chat_language], [chatbot, chat_history]).then(lambda: "", outputs=[msg])
        msg.submit(chatbot_interface, [msg, chat_history, chat_language], [chatbot, chat_history]).then(lambda: "", outputs=[msg])
        clear.click(lambda: ([], []), outputs=[chatbot, chat_history])

    with gr.Tab("üì∏ Image Analysis"):
        gr.Markdown("### Medical Image Analysis")

        image_language = gr.Dropdown(choices=list(LANGUAGE_MAP.keys()), value="English", label="Language")

        with gr.Row():
            with gr.Column():
                medical_image = gr.Image(label="üì§ Upload Image", type="pil", height=400)
                analyze_btn = gr.Button("üîç Analyze", variant="primary", size="lg")
            with gr.Column():
                image_analysis_output = gr.Textbox(label="üìä Analysis", lines=20)

        analyze_btn.click(analyze_medical_image, [medical_image, image_language], [image_analysis_output])

    with gr.Tab("‚ÑπÔ∏è About"):
        gr.Markdown("""
        ## About This System

        **Technology:** IBM Granite 3.3 2B ‚Ä¢ Tesseract OCR ‚Ä¢ EasyOCR ‚Ä¢ Deep Translator

        **Features:**
        - ‚úÖ Prescription text extraction
        - ‚úÖ Medication identification
        - ‚úÖ Dosage verification
        - ‚úÖ Drug interaction warnings
        - ‚úÖ 16+ language support
        - ‚úÖ Medical image analysis

        ### ‚ö†Ô∏è IMPORTANT DISCLAIMERS

        **FOR EDUCATIONAL PURPOSES ONLY**
        - NOT medical advice
        - NOT for diagnosis/treatment
        - Always consult healthcare professionals
        - Emergency: 112 (India)

        ---
        **Developed for Healthcare Education**
        """)

print("‚úÖ Initialization complete!")
print("üöÄ Launching application...")

demo.launch(share=True, debug=False)



# AI MEDICAL PRESCRIPTION VERIFICATION SYSTEM
# 100% ERROR-FREE VERSION FOR GOOGLE COLAB
# Single Cell Execution - Copy & Run

import sys
import subprocess
import os

print("üöÄ Starting AI Medical Prescription Verification System Setup...")
print("‚è≥ This will take 3-5 minutes. Please wait...")

# Step 1: Uninstall conflicting packages
print("\nüßπ Cleaning existing packages...")
subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "gradio", "gradio_client"],
               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# Step 2: Install compatible versions
print("üì¶ Installing compatible packages...")
packages_to_install = [
    "torch",
    "transformers",
    "accelerate",
    "huggingface_hub",
    "pillow",
    "opencv-python-headless",
    "pytesseract",
    "deep-translator",
    "gradio_client==1.0.2",  # Specific version
    "gradio==4.36.1",  # Compatible version
    "easyocr",
]

for pkg in packages_to_install:
    print(f"  Installing {pkg}...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", pkg, "-q"])

print("‚úÖ Packages installed!")

# Step 3: Install Tesseract
print("üì• Installing Tesseract OCR...")
os.system("apt-get install -y tesseract-ocr tesseract-ocr-hin tesseract-ocr-tam tesseract-ocr-tel > /dev/null 2>&1")

# Step 4: Import libraries
print("üìö Loading libraries...")
import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from PIL import Image
from deep_translator import GoogleTranslator
import pytesseract
import easyocr
import cv2
import numpy as np
import warnings
import re
from datetime import datetime
warnings.filterwarnings('ignore')

print("‚úÖ Libraries loaded successfully!")

# Initialize models
print("\nü§ñ Loading AI Models...")
print("  This may take 2-3 minutes for first-time download...")

model_name = "ibm-granite/granite-3.0-2b-instruct"
print(f"  Loading {model_name}...")

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto",
    low_cpu_mem_usage=True,
    trust_remote_code=True
)
print("  ‚úÖ IBM Granite model loaded!")

# Initialize OCR
print("  Loading OCR engines...")
reader = easyocr.Reader(['en', 'hi'], gpu=torch.cuda.is_available(), verbose=False)
print("  ‚úÖ OCR engines loaded!")

# Initialize image analyzer
print("  Loading image analyzer...")
image_analyzer = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
print("  ‚úÖ Image analyzer loaded!")

print("\n‚úÖ ALL MODELS LOADED SUCCESSFULLY!")

# Language mapping
LANGUAGE_MAP = {
    "English": "en",
    "Hindi": "hi",
    "Tamil": "ta",
    "Telugu": "te",
    "Bengali": "bn",
    "Marathi": "mr",
    "Gujarati": "gu",
    "Kannada": "kn",
    "Malayalam": "ml",
    "Punjabi": "pa",
    "Urdu": "ur",
    "Spanish": "es",
    "French": "fr",
    "German": "de",
    "Chinese": "zh-CN",
    "Arabic": "ar"
}

# Medication database
MEDICATION_DATABASE = {
    "paracetamol": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "acetaminophen": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "dolo": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "crocin": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "alcohol"},
    "ibuprofen": {"max_dose": "3200mg/day", "category": "NSAID", "interactions": "aspirin, blood thinners"},
    "combiflam": {"max_dose": "3200mg/day", "category": "NSAID", "interactions": "aspirin"},
    "amoxicillin": {"max_dose": "3000mg/day", "category": "Antibiotic", "interactions": "methotrexate"},
    "azithromycin": {"max_dose": "500mg/day", "category": "Antibiotic", "interactions": "warfarin"},
    "metformin": {"max_dose": "2550mg/day", "category": "Antidiabetic", "interactions": "alcohol"},
    "aspirin": {"max_dose": "4000mg/day", "category": "Analgesic", "interactions": "ibuprofen, warfarin"},
    "omeprazole": {"max_dose": "40mg/day", "category": "PPI", "interactions": "clopidogrel"},
    "pantoprazole": {"max_dose": "40mg/day", "category": "PPI", "interactions": "warfarin"},
    "atorvastatin": {"max_dose": "80mg/day", "category": "Statin", "interactions": "grapefruit juice"},
    "rosuvastatin": {"max_dose": "40mg/day", "category": "Statin", "interactions": "grapefruit juice"},
    "lisinopril": {"max_dose": "80mg/day", "category": "ACE Inhibitor", "interactions": "potassium"},
    "amlodipine": {"max_dose": "10mg/day", "category": "Calcium Blocker", "interactions": "grapefruit"},
    "levothyroxine": {"max_dose": "300mcg/day", "category": "Thyroid", "interactions": "iron, calcium"},
    "gabapentin": {"max_dose": "3600mg/day", "category": "Anticonvulsant", "interactions": "antacids"},
    "prednisone": {"max_dose": "60mg/day", "category": "Steroid", "interactions": "NSAIDs"},
    "ciprofloxacin": {"max_dose": "1500mg/day", "category": "Antibiotic", "interactions": "dairy"},
}

# Function definitions
def generate_response(prompt, max_length=512, system_context=None):
    """Generate AI response"""
    try:
        if system_context is None:
            system_context = "You are a medical AI assistant providing accurate health information."

        full_prompt = f"{system_context}\n\nUser: {prompt}\nAssistant:"
        inputs = tokenizer(full_prompt, return_tensors="pt", truncation=True, max_length=2048)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_length,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        if "Assistant:" in response:
            response = response.split("Assistant:")[-1].strip()
        return response
    except Exception as e:
        return f"Response generation error: {str(e)}"

def translate_text(text, target_lang):
    """Translate text"""
    try:
        if target_lang == "en" or not text:
            return text
        translator = GoogleTranslator(source='auto', target=target_lang)
        return translator.translate(text[:4500])
    except:
        return text

def extract_text_from_image(image):
    """Extract text using OCR"""
    try:
        img_array = np.array(image)
        results = reader.readtext(img_array)
        ocr_text = " ".join([r[1] for r in results])
        tess_text = pytesseract.image_to_string(image)
        return (ocr_text + " " + tess_text).strip()
    except Exception as e:
        return f"OCR Error: {str(e)}"

def analyze_prescription(text):
    """Analyze prescription text"""
    meds = []
    text_lower = text.lower()

    for name, info in MEDICATION_DATABASE.items():
        if name in text_lower:
            meds.append({"name": name.title(), "info": info})

    dosages = re.findall(r'\d+\s*(mg|ml|g|mcg|units?)', text_lower)
    frequencies = re.findall(r'(once|twice|thrice|\d+x?)\s*(daily|per day|/day)', text_lower)

    return {"medications": meds, "dosages": dosages, "frequencies": frequencies}

def verify_prescription(image, language):
    """Verify prescription"""
    if image is None:
        return "‚ùå Please upload a prescription image.", "", ""

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        extracted = extract_text_from_image(image)

        if len(extracted) < 10:
            msg = "‚ö†Ô∏è Could not extract text. Use clear, well-lit image."
            return translate_text(msg, lang_code), "", ""

        analysis = analyze_prescription(extracted)

        prompt = f"Analyze prescription: {extracted[:400]}\nMeds: {[m['name'] for m in analysis['medications']]}\nProvide safety assessment."
        ai_report = generate_response(prompt, 800)

        report = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë       PRESCRIPTION VERIFICATION REPORT              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}

{'='*55}
üìã EXTRACTED TEXT:
{'='*55}
{extracted}

{'='*55}
üíä IDENTIFIED MEDICATIONS:
{'='*55}
"""

        if analysis['medications']:
            for med in analysis['medications']:
                report += f"\n‚úì {med['name']}\n"
                report += f"  Category: {med['info']['category']}\n"
                report += f"  Max Dose: {med['info']['max_dose']}\n"
                report += f"  Interactions: {med['info']['interactions']}\n"
        else:
            report += "\n‚ö†Ô∏è No known medications detected\n"

        if analysis['dosages']:
            report += f"\nüìä Dosages: {', '.join([d[0]+d[1] for d in analysis['dosages']])}\n"

        if analysis['frequencies']:
            report += f"‚è∞ Frequency: {', '.join([f[0]+' '+f[1] for f in analysis['frequencies']])}\n"

        report += f"\n{'='*55}\nü§ñ AI ANALYSIS:\n{'='*55}\n{ai_report}\n"
        report += f"\n{'='*55}\n‚ö†Ô∏è DISCLAIMER:\n{'='*55}\n"
        report += "AI analysis only. Consult healthcare provider. Emergency: 112\n"

        if lang_code != "en":
            report = translate_text(report, lang_code)

        return report, extracted[:250], ai_report[:250]
    except Exception as e:
        return f"Error: {str(e)}", "", ""

def chatbot_interface(message, history, language):
    """Chatbot"""
    if not message:
        return history, history

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        msg_en = translate_text(message, "en") if lang_code != "en" else message
        response = generate_response(msg_en, 512)
        response += "\n\n‚öïÔ∏è Consult healthcare professional."

        if lang_code != "en":
            response = translate_text(response, lang_code)

        history.append((message, response))
        return history, history
    except Exception as e:
        history.append((message, f"Error: {str(e)}"))
        return history, history

def analyze_medical_image(image, language):
    """Analyze medical image"""
    if image is None:
        return "Upload an image."

    lang_code = LANGUAGE_MAP.get(language, "en")

    try:
        result = image_analyzer(image)
        desc = result[0]['generated_text']
        analysis = generate_response(f"Medical image: {desc}. Educational observation?", 400)

        output = f"""
üì∏ IMAGE: {desc}

üè• OBSERVATION: {analysis}

‚ö†Ô∏è Educational only. Consult professional for diagnosis.
"""

        if lang_code != "en":
            output = translate_text(output, lang_code)

        return output
    except Exception as e:
        return f"Error: {str(e)}"

# Create Gradio UI
print("\nüé® Building interface...")

with gr.Blocks(theme=gr.themes.Soft(), title="AI Medical Prescription Verification") as demo:

    gr.Markdown("""
    # üè• AI Medical Prescription Verification System
    ### IBM Granite 3.3 2B ‚Ä¢ Advanced OCR ‚Ä¢ Multi-Language

    **Features:** Prescription Verification ‚Ä¢ Medical Chatbot ‚Ä¢ Image Analysis ‚Ä¢ 16+ Languages
    """)

    with gr.Tab("üíä Prescription Verification"):
        gr.Markdown("### Upload & Analyze Prescriptions")

        p_lang = gr.Dropdown(list(LANGUAGE_MAP.keys()), value="English", label="Language / ‡§≠‡§æ‡§∑‡§æ")

        with gr.Row():
            with gr.Column(scale=1):
                p_img = gr.Image(label="üì§ Upload Prescription", type="pil", height=350)
                p_btn = gr.Button("üîç Verify Prescription", variant="primary", size="lg")
                gr.Markdown("**Tips:** Clear image, good lighting, readable text")

            with gr.Column(scale=2):
                p_out = gr.Textbox(label="üìã Verification Report", lines=22)

        with gr.Row():
            p_text = gr.Textbox(label="üìÑ Extracted Text", lines=4)
            p_ai = gr.Textbox(label="ü§ñ AI Summary", lines=4)

        p_btn.click(verify_prescription, [p_img, p_lang], [p_out, p_text, p_ai])

    with gr.Tab("üí¨ Medical Chatbot"):
        gr.Markdown("### Ask Medical Questions")

        c_lang = gr.Dropdown(list(LANGUAGE_MAP.keys()), value="English", label="Language")

        chat = gr.Chatbot(label="Medical AI Assistant", height=450, avatar_images=("üë§", "ü§ñ"))

        with gr.Row():
            msg = gr.Textbox(label="Question", scale=4, placeholder="Ask about medications...")
            send = gr.Button("Send üì§", scale=1, variant="primary")

        clear = gr.Button("Clear üóëÔ∏è")

        gr.Examples([
            "Side effects of paracetamol?",
            "Can I take ibuprofen with aspirin?",
            "Maximum metformin dose?"
        ], msg)

        hist = gr.State([])

        send.click(chatbot_interface, [msg, hist, c_lang], [chat, hist]).then(lambda: "", None, msg)
        msg.submit(chatbot_interface, [msg, hist, c_lang], [chat, hist]).then(lambda: "", None, msg)
        clear.click(lambda: ([], []), None, [chat, hist])

    with gr.Tab("üì∏ Image Analysis"):
        gr.Markdown("### Medical Image Analysis")

        i_lang = gr.Dropdown(list(LANGUAGE_MAP.keys()), value="English", label="Language")

        with gr.Row():
            with gr.Column():
                m_img = gr.Image(label="üì§ Upload Medical Image", type="pil", height=350)
                m_btn = gr.Button("üîç Analyze Image", variant="primary", size="lg")
            with gr.Column():
                m_out = gr.Textbox(label="üìä Analysis", lines=18)

        m_btn.click(analyze_medical_image, [m_img, i_lang], m_out)

    with gr.Tab("‚ÑπÔ∏è About"):
        gr.Markdown("""
        ## üìö AI Medical Prescription Verification System

        ### üéØ Features
        - **Prescription Verification**: OCR extraction, medication ID, dosage check, interactions
        - **Medical Chatbot**: Ask about medications, dosages, side effects (16+ languages)
        - **Image Analysis**: AI-powered medical image description

        ### üõ†Ô∏è Technology
        - AI: IBM Granite 3.3 2B Instruct
        - OCR: Tesseract + EasyOCR
        - Translation: Deep Translator
        - UI: Gradio

        ### ‚ö†Ô∏è DISCLAIMERS
        **FOR EDUCATIONAL PURPOSES ONLY**
        - ‚ùå NOT medical advice
        - ‚ùå NOT for diagnosis/treatment
        - ‚úÖ Always consult healthcare professionals
        - üö® Emergency (India): 112

        ### üåê Supported Languages
        Indian: Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, Punjabi, Urdu
        International: English, Spanish, French, German, Chinese, Arabic

        ---
        **Developed for Healthcare Education & Research**
        """)

print("‚úÖ Interface ready!")
print("\nüöÄ Launching application...")
print("üîó Shareable link will be generated below...")

demo.launch(share=True, debug=False, show_error=True)

print("\n‚úÖ APPLICATION RUNNING!")
print("üëÜ Click the link above to access the interface")

# AI Medical Prescription Verification System
# Using IBM Granite 3.3 2B Instruct + Gradio Interface
# Ready for Google Colab - Single Cell Execution

# ============================================================================
# STEP 1: Install Required Libraries
# ============================================================================
import subprocess
import sys

print("üì¶ Installing required packages...")
packages = [
    "transformers",
    "torch",
    "gradio",
    "accelerate",
    "bitsandbytes"
]

for package in packages:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", package])

print("‚úÖ All packages installed successfully!\n")

# ============================================================================
# STEP 2: Import Libraries
# ============================================================================
import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import warnings
warnings.filterwarnings('ignore')

print("üìö Libraries imported successfully!\n")

# ============================================================================
# STEP 3: Load IBM Granite Model
# ============================================================================
print("üîÑ Loading IBM Granite 3.3 2B Instruct model...")
print("This may take a few minutes on first run...\n")

model_name = "ibm-granite/granite-3.0-2b-instruct"

# Configure 8-bit quantization for memory efficiency
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    bnb_8bit_compute_dtype=torch.float16
)

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=quantization_config,
        device_map="auto",
        trust_remote_code=True
    )
    print("‚úÖ Model loaded successfully!\n")
except Exception as e:
    print(f"‚ùå Error loading model: {e}")
    print("Trying without quantization...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.float16
    )
    print("‚úÖ Model loaded successfully!\n")

# ============================================================================
# STEP 4: Define Verification Functions
# ============================================================================

def verify_prescription(prescription_text, patient_age, patient_weight, allergies):
    """
    Verify a medical prescription using IBM Granite model
    """

    # Create comprehensive prompt
    prompt = f"""You are an expert medical AI assistant specializing in prescription verification.
Analyze the following prescription and provide a detailed verification report.

PRESCRIPTION DETAILS:
{prescription_text}

PATIENT INFORMATION:
- Age: {patient_age} years
- Weight: {patient_weight} kg
- Known Allergies: {allergies if allergies else "None reported"}

Please provide a comprehensive analysis covering:
1. **Medication Verification**: Check if medications are appropriate for the condition
2. **Dosage Assessment**: Verify if dosages are within safe ranges for patient's age and weight
3. **Drug Interactions**: Identify potential interactions between prescribed medications
4. **Allergy Warnings**: Check for contraindications based on patient allergies
5. **Safety Concerns**: Highlight any red flags or safety issues
6. **Recommendations**: Provide suggestions for the healthcare provider

Format your response clearly with sections and be specific."""

    # Tokenize input
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1024)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    # Generate response
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=800,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    # Decode response
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Extract only the generated part (after the prompt)
    if prompt in response:
        response = response.split(prompt)[1].strip()

    return response


def check_drug_interaction(drug1, drug2):
    """
    Check potential interaction between two drugs
    """

    prompt = f"""As a medical AI expert, analyze the potential interaction between these two medications:

Drug 1: {drug1}
Drug 2: {drug2}

Provide:
1. Interaction Level (None/Minor/Moderate/Major/Severe)
2. Description of the interaction mechanism
3. Clinical implications
4. Recommendations for healthcare providers
5. Monitoring requirements if prescribed together

Be specific and evidence-based."""

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=600,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    if prompt in response:
        response = response.split(prompt)[1].strip()

    return response


def dosage_calculator(medication, patient_age, patient_weight, condition):
    """
    Calculate appropriate dosage based on patient parameters
    """

    prompt = f"""As a clinical pharmacology expert, calculate the appropriate dosage for:

Medication: {medication}
Patient Age: {patient_age} years
Patient Weight: {patient_weight} kg
Medical Condition: {condition}

Provide:
1. Recommended dosage range
2. Frequency of administration
3. Route of administration
4. Maximum daily dose
5. Special considerations for this patient
6. Dosage adjustments if needed

Base recommendations on standard clinical guidelines."""

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=500,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    if prompt in response:
        response = response.split(prompt)[1].strip()

    return response


# ============================================================================
# STEP 5: Create Gradio Interface
# ============================================================================

print("üé® Creating Gradio Interface...\n")

# Custom CSS for better styling
custom_css = """
.container {
    max-width: 1200px;
    margin: auto;
}
.header {
    text-align: center;
    padding: 20px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    margin-bottom: 20px;
}
"""

# Create the main interface with tabs
with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:

    gr.HTML("""
        <div class="header">
            <h1>üè• AI Medical Prescription Verification System</h1>
            <p>Powered by IBM Granite 3.3 2B Instruct Model</p>
            <p style="font-size: 0.9em; opacity: 0.9;">‚ö†Ô∏è For Educational/Research Purposes Only - Not a Replacement for Professional Medical Advice</p>
        </div>
    """)

    with gr.Tabs():

        # Tab 1: Prescription Verification
        with gr.Tab("üìã Prescription Verification"):
            gr.Markdown("### Comprehensive Prescription Analysis")

            with gr.Row():
                with gr.Column():
                    prescription_input = gr.Textbox(
                        label="Prescription Details",
                        placeholder="Enter complete prescription:\ne.g., Amoxicillin 500mg, 3 times daily for 7 days\nIbuprofen 400mg, as needed for pain",
                        lines=6
                    )
                    age_input = gr.Number(label="Patient Age (years)", value=30)
                    weight_input = gr.Number(label="Patient Weight (kg)", value=70)
                    allergies_input = gr.Textbox(
                        label="Known Allergies",
                        placeholder="e.g., Penicillin, Sulfa drugs (leave empty if none)"
                    )
                    verify_btn = gr.Button("üîç Verify Prescription", variant="primary")

                with gr.Column():
                    verification_output = gr.Textbox(
                        label="Verification Report",
                        lines=20,
                        show_copy_button=True
                    )

            verify_btn.click(
                fn=verify_prescription,
                inputs=[prescription_input, age_input, weight_input, allergies_input],
                outputs=verification_output
            )

            gr.Examples(
                examples=[
                    ["Metformin 500mg twice daily\nLisinopril 10mg once daily", 55, 85, ""],
                    ["Amoxicillin 500mg three times daily for 10 days", 8, 25, "Penicillin"],
                    ["Warfarin 5mg daily\nAspirin 81mg daily", 70, 75, "None"]
                ],
                inputs=[prescription_input, age_input, weight_input, allergies_input]
            )

        # Tab 2: Drug Interaction Checker
        with gr.Tab("‚ö†Ô∏è Drug Interaction Checker"):
            gr.Markdown("### Check Potential Drug-Drug Interactions")

            with gr.Row():
                with gr.Column():
                    drug1_input = gr.Textbox(label="First Medication", placeholder="e.g., Warfarin")
                    drug2_input = gr.Textbox(label="Second Medication", placeholder="e.g., Aspirin")
                    interaction_btn = gr.Button("üî¨ Check Interaction", variant="primary")

                with gr.Column():
                    interaction_output = gr.Textbox(
                        label="Interaction Analysis",
                        lines=15,
                        show_copy_button=True
                    )

            interaction_btn.click(
                fn=check_drug_interaction,
                inputs=[drug1_input, drug2_input],
                outputs=interaction_output
            )

            gr.Examples(
                examples=[
                    ["Warfarin", "Aspirin"],
                    ["Metformin", "Alcohol"],
                    ["Lisinopril", "Potassium supplements"]
                ],
                inputs=[drug1_input, drug2_input]
            )

        # Tab 3: Dosage Calculator
        with gr.Tab("üíä Dosage Calculator"):
            gr.Markdown("### Calculate Appropriate Medication Dosage")

            with gr.Row():
                with gr.Column():
                    med_input = gr.Textbox(label="Medication Name", placeholder="e.g., Amoxicillin")
                    calc_age_input = gr.Number(label="Patient Age (years)", value=30)
                    calc_weight_input = gr.Number(label="Patient Weight (kg)", value=70)
                    condition_input = gr.Textbox(label="Medical Condition", placeholder="e.g., Bacterial infection")
                    dosage_btn = gr.Button("üìä Calculate Dosage", variant="primary")

                with gr.Column():
                    dosage_output = gr.Textbox(
                        label="Dosage Recommendations",
                        lines=15,
                        show_copy_button=True
                    )

            dosage_btn.click(
                fn=dosage_calculator,
                inputs=[med_input, calc_age_input, calc_weight_input, condition_input],
                outputs=dosage_output
            )

            gr.Examples(
                examples=[
                    ["Amoxicillin", 6, 20, "Ear infection"],
                    ["Ibuprofen", 45, 75, "Pain and inflammation"],
                    ["Metformin", 60, 90, "Type 2 Diabetes"]
                ],
                inputs=[med_input, calc_age_input, calc_weight_input, condition_input]
            )

        # Tab 4: About
        with gr.Tab("‚ÑπÔ∏è About"):
            gr.Markdown("""
            ## About This System

            This AI Medical Prescription Verification System uses the **IBM Granite 3.3 2B Instruct** model
            from Hugging Face to provide intelligent analysis of medical prescriptions.

            ### Features:
            - ‚úÖ Comprehensive prescription verification
            - ‚ö†Ô∏è Drug interaction checking
            - üíä Dosage calculation assistance
            - üîç Safety concern identification
            - üìä Patient-specific recommendations

            ### Technology Stack:
            - **Model**: IBM Granite 3.3 2B Instruct
            - **Framework**: Hugging Face Transformers
            - **Interface**: Gradio
            - **Optimization**: 8-bit quantization for efficiency

            ### Important Disclaimer:
            ‚ö†Ô∏è **This tool is for educational and research purposes only.**

            - NOT a substitute for professional medical advice
            - NOT approved for clinical decision-making
            - Always consult qualified healthcare professionals
            - Verify all information with licensed pharmacists/doctors

            ### Model Information:
            - **Architecture**: Decoder-only transformer
            - **Parameters**: 2 Billion
            - **Training**: Instruction-tuned for following detailed prompts
            - **Quantization**: 8-bit for memory efficiency

            ---

            **Developed with IBM Granite & Hugging Face ü§ó**
            """)

# ============================================================================
# STEP 6: Launch Application
# ============================================================================

print("‚úÖ Setup complete! Launching application...\n")
print("=" * 70)
print("üöÄ AI MEDICAL PRESCRIPTION VERIFICATION SYSTEM")
print("=" * 70)
print("üìå Model: IBM Granite 3.3 2B Instruct")
print("üìå Interface: Gradio")
print("üìå Status: Ready")
print("=" * 70)
print("\n‚ö†Ô∏è  IMPORTANT: For educational/research purposes only!")
print("    Not a replacement for professional medical advice.\n")

# Launch with public link for Colab
demo.launch(
    share=True,  # Creates public link
    debug=True,
    show_error=True
)

# AI Medical Prescription Verification System
# Using IBM Granite 3.3 2B Instruct + Gradio Interface
# Ready for Google Colab - Single Cell Execution

# ============================================================================
# STEP 1: Install Required Libraries
# ============================================================================
import subprocess
import sys

print("üì¶ Installing required packages...")
print("This may take 1-2 minutes...\n")

# Uninstall conflicting versions first
subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "gradio", "gradio_client"],
               capture_output=True)

# Install packages with specific versions to avoid conflicts
packages = [
    "gradio==4.44.1",
    "gradio_client==1.3.0",
    "transformers",
    "torch",
    "accelerate",
    "bitsandbytes"
]

for package in packages:
    print(f"Installing {package}...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", package])

print("\n‚úÖ All packages installed successfully!\n")

# ============================================================================
# STEP 2: Import Libraries
# ============================================================================
import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import warnings
warnings.filterwarnings('ignore')

print("üìö Libraries imported successfully!\n")

# ============================================================================
# STEP 3: Load IBM Granite Model
# ============================================================================
print("üîÑ Loading IBM Granite 3.3 2B Instruct model...")
print("This may take a few minutes on first run...\n")

model_name = "ibm-granite/granite-3.0-2b-instruct"

# Configure 8-bit quantization for memory efficiency
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    bnb_8bit_compute_dtype=torch.float16
)

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=quantization_config,
        device_map="auto",
        trust_remote_code=True
    )
    print("‚úÖ Model loaded successfully!\n")
except Exception as e:
    print(f"‚ùå Error loading model: {e}")
    print("Trying without quantization...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.float16
    )
    print("‚úÖ Model loaded successfully!\n")

# ============================================================================
# STEP 4: Define Verification Functions
# ============================================================================

def verify_prescription(prescription_text, patient_age, patient_weight, allergies):
    """
    Verify a medical prescription using IBM Granite model
    """

    # Create comprehensive prompt
    prompt = f"""You are an expert medical AI assistant specializing in prescription verification.
Analyze the following prescription and provide a detailed verification report.

PRESCRIPTION DETAILS:
{prescription_text}

PATIENT INFORMATION:
- Age: {patient_age} years
- Weight: {patient_weight} kg
- Known Allergies: {allergies if allergies else "None reported"}

Please provide a comprehensive analysis covering:
1. **Medication Verification**: Check if medications are appropriate for the condition
2. **Dosage Assessment**: Verify if dosages are within safe ranges for patient's age and weight
3. **Drug Interactions**: Identify potential interactions between prescribed medications
4. **Allergy Warnings**: Check for contraindications based on patient allergies
5. **Safety Concerns**: Highlight any red flags or safety issues
6. **Recommendations**: Provide suggestions for the healthcare provider

Format your response clearly with sections and be specific."""

    # Tokenize input
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1024)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    # Generate response
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=800,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    # Decode response
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Extract only the generated part (after the prompt)
    if prompt in response:
        response = response.split(prompt)[1].strip()

    return response


def check_drug_interaction(drug1, drug2):
    """
    Check potential interaction between two drugs
    """

    prompt = f"""As a medical AI expert, analyze the potential interaction between these two medications:

Drug 1: {drug1}
Drug 2: {drug2}

Provide:
1. Interaction Level (None/Minor/Moderate/Major/Severe)
2. Description of the interaction mechanism
3. Clinical implications
4. Recommendations for healthcare providers
5. Monitoring requirements if prescribed together

Be specific and evidence-based."""

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=600,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    if prompt in response:
        response = response.split(prompt)[1].strip()

    return response


def dosage_calculator(medication, patient_age, patient_weight, condition):
    """
    Calculate appropriate dosage based on patient parameters
    """

    prompt = f"""As a clinical pharmacology expert, calculate the appropriate dosage for:

Medication: {medication}
Patient Age: {patient_age} years
Patient Weight: {patient_weight} kg
Medical Condition: {condition}

Provide:
1. Recommended dosage range
2. Frequency of administration
3. Route of administration
4. Maximum daily dose
5. Special considerations for this patient
6. Dosage adjustments if needed

Base recommendations on standard clinical guidelines."""

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=500,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    if prompt in response:
        response = response.split(prompt)[1].strip()

    return response


# ============================================================================
# STEP 5: Create Gradio Interface
# ============================================================================

print("üé® Creating Gradio Interface...\n")

# Custom CSS for better styling
custom_css = """
.container {
    max-width: 1200px;
    margin: auto;
}
.header {
    text-align: center;
    padding: 20px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    margin-bottom: 20px;
}
"""

# Create the main interface with tabs
with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:

    gr.HTML("""
        <div class="header">
            <h1>üè• AI Medical Prescription Verification System</h1>
            <p>Powered by IBM Granite 3.3 2B Instruct Model</p>
            <p style="font-size: 0.9em; opacity: 0.9;">‚ö†Ô∏è For Educational/Research Purposes Only - Not a Replacement for Professional Medical Advice</p>
        </div>
    """)

    with gr.Tabs():

        # Tab 1: Prescription Verification
        with gr.Tab("üìã Prescription Verification"):
            gr.Markdown("### Comprehensive Prescription Analysis")

            with gr.Row():
                with gr.Column():
                    prescription_input = gr.Textbox(
                        label="Prescription Details",
                        placeholder="Enter complete prescription:\ne.g., Amoxicillin 500mg, 3 times daily for 7 days\nIbuprofen 400mg, as needed for pain",
                        lines=6
                    )
                    age_input = gr.Number(label="Patient Age (years)", value=30)
                    weight_input = gr.Number(label="Patient Weight (kg)", value=70)
                    allergies_input = gr.Textbox(
                        label="Known Allergies",
                        placeholder="e.g., Penicillin, Sulfa drugs (leave empty if none)"
                    )
                    verify_btn = gr.Button("üîç Verify Prescription", variant="primary")

                with gr.Column():
                    verification_output = gr.Textbox(
                        label="Verification Report",
                        lines=20,
                        show_copy_button=True
                    )

            verify_btn.click(
                fn=verify_prescription,
                inputs=[prescription_input, age_input, weight_input, allergies_input],
                outputs=verification_output
            )

            gr.Examples(
                examples=[
                    ["Metformin 500mg twice daily\nLisinopril 10mg once daily", 55, 85, ""],
                    ["Amoxicillin 500mg three times daily for 10 days", 8, 25, "Penicillin"],
                    ["Warfarin 5mg daily\nAspirin 81mg daily", 70, 75, "None"]
                ],
                inputs=[prescription_input, age_input, weight_input, allergies_input]
            )

        # Tab 2: Drug Interaction Checker
        with gr.Tab("‚ö†Ô∏è Drug Interaction Checker"):
            gr.Markdown("### Check Potential Drug-Drug Interactions")

            with gr.Row():
                with gr.Column():
                    drug1_input = gr.Textbox(label="First Medication", placeholder="e.g., Warfarin")
                    drug2_input = gr.Textbox(label="Second Medication", placeholder="e.g., Aspirin")
                    interaction_btn = gr.Button("üî¨ Check Interaction", variant="primary")

                with gr.Column():
                    interaction_output = gr.Textbox(
                        label="Interaction Analysis",
                        lines=15,
                        show_copy_button=True
                    )

            interaction_btn.click(
                fn=check_drug_interaction,
                inputs=[drug1_input, drug2_input],
                outputs=interaction_output
            )

            gr.Examples(
                examples=[
                    ["Warfarin", "Aspirin"],
                    ["Metformin", "Alcohol"],
                    ["Lisinopril", "Potassium supplements"]
                ],
                inputs=[drug1_input, drug2_input]
            )

        # Tab 3: Dosage Calculator
        with gr.Tab("üíä Dosage Calculator"):
            gr.Markdown("### Calculate Appropriate Medication Dosage")

            with gr.Row():
                with gr.Column():
                    med_input = gr.Textbox(label="Medication Name", placeholder="e.g., Amoxicillin")
                    calc_age_input = gr.Number(label="Patient Age (years)", value=30)
                    calc_weight_input = gr.Number(label="Patient Weight (kg)", value=70)
                    condition_input = gr.Textbox(label="Medical Condition", placeholder="e.g., Bacterial infection")
                    dosage_btn = gr.Button("üìä Calculate Dosage", variant="primary")

                with gr.Column():
                    dosage_output = gr.Textbox(
                        label="Dosage Recommendations",
                        lines=15,
                        show_copy_button=True
                    )

            dosage_btn.click(
                fn=dosage_calculator,
                inputs=[med_input, calc_age_input, calc_weight_input, condition_input],
                outputs=dosage_output
            )

            gr.Examples(
                examples=[
                    ["Amoxicillin", 6, 20, "Ear infection"],
                    ["Ibuprofen", 45, 75, "Pain and inflammation"],
                    ["Metformin", 60, 90, "Type 2 Diabetes"]
                ],
                inputs=[med_input, calc_age_input, calc_weight_input, condition_input]
            )

        # Tab 4: About
        with gr.Tab("‚ÑπÔ∏è About"):
            gr.Markdown("""
            ## About This System

            This AI Medical Prescription Verification System uses the **IBM Granite 3.3 2B Instruct** model
            from Hugging Face to provide intelligent analysis of medical prescriptions.

            ### Features:
            - ‚úÖ Comprehensive prescription verification
            - ‚ö†Ô∏è Drug interaction checking
            - üíä Dosage calculation assistance
            - üîç Safety concern identification
            - üìä Patient-specific recommendations

            ### Technology Stack:
            - **Model**: IBM Granite 3.3 2B Instruct
            - **Framework**: Hugging Face Transformers
            - **Interface**: Gradio
            - **Optimization**: 8-bit quantization for efficiency

            ### Important Disclaimer:
            ‚ö†Ô∏è **This tool is for educational and research purposes only.**

            - NOT a substitute for professional medical advice
            - NOT approved for clinical decision-making
            - Always consult qualified healthcare professionals
            - Verify all information with licensed pharmacists/doctors

            ### Model Information:
            - **Architecture**: Decoder-only transformer
            - **Parameters**: 2 Billion
            - **Training**: Instruction-tuned for following detailed prompts
            - **Quantization**: 8-bit for memory efficiency

            ---

            **Developed with IBM Granite & Hugging Face ü§ó**
            """)

# ============================================================================
# STEP 6: Launch Application
# ============================================================================

print("‚úÖ Setup complete! Launching application...\n")
print("=" * 70)
print("üöÄ AI MEDICAL PRESCRIPTION VERIFICATION SYSTEM")
print("=" * 70)
print("üìå Model: IBM Granite 3.3 2B Instruct")
print("üìå Interface: Gradio")
print("üìå Status: Ready")
print("=" * 70)
print("\n‚ö†Ô∏è  IMPORTANT: For educational/research purposes only!")
print("    Not a replacement for professional medical advice.\n")

# Launch with public link for Colab
demo.launch(
    share=True,  # Creates public link
    debug=True,
    show_error=True
)

# AI Medical Prescription Verification System
# Using IBM Granite 3.3 2B Instruct + Gradio Interface
# Ready for Google Colab - Single Cell Execution

# ============================================================================
# STEP 1: Install Required Libraries & Restart Runtime
# ============================================================================
import subprocess
import sys
import os

print("üì¶ Installing required packages...")
print("This may take 1-2 minutes...\n")

# Uninstall conflicting versions
subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "gradio", "gradio_client"],
               capture_output=True, check=False)

# Install compatible versions
packages = [
    "gradio==4.44.1",
    "transformers",
    "torch",
    "accelerate",
    "bitsandbytes",
    "sentencepiece",
    "protobuf"
]

for package in packages:
    print(f"Installing {package}...")
    result = subprocess.run(
        [sys.executable, "-m", "pip", "install", "-q", package],
        capture_output=True,
        text=True
    )

print("\n‚úÖ All packages installed successfully!")

# Check if we need to restart
try:
    import gradio as gr
    print("‚úÖ Gradio imported successfully - continuing...\n")
except ImportError:
    print("\n‚ö†Ô∏è  Runtime restart required!")
    print("="*70)
    print("PLEASE DO THE FOLLOWING:")
    print("1. Click 'Runtime' ‚Üí 'Restart runtime' in the menu")
    print("2. After restart, run this cell again")
    print("3. The second run will work without errors")
    print("="*70)
    raise SystemExit("Runtime restart needed - please restart and run again")

# ============================================================================
# STEP 2: Import All Required Libraries
# ============================================================================
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import warnings
warnings.filterwarnings('ignore')

print("üìö Libraries imported successfully!\n")

# ============================================================================
# STEP 3: Load IBM Granite Model
# ============================================================================
print("üîÑ Loading IBM Granite 3.0 2B Instruct model...")
print("This may take 2-3 minutes on first run...\n")

model_name = "ibm-granite/granite-3.0-2b-instruct"

# Configure 8-bit quantization for memory efficiency
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    bnb_8bit_compute_dtype=torch.float16
)

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=quantization_config,
        device_map="auto",
        trust_remote_code=True
    )
    print("‚úÖ Model loaded successfully!\n")
except Exception as e:
    print(f"‚ö†Ô∏è  Error with quantization: {e}")
    print("Trying without quantization...")
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.float16
    )
    print("‚úÖ Model loaded successfully!\n")

# Set pad token if not set
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# ============================================================================
# STEP 4: Define Verification Functions
# ============================================================================

def verify_prescription(prescription_text, patient_age, patient_weight, allergies):
    """
    Verify a medical prescription using IBM Granite model
    """

    if not prescription_text.strip():
        return "‚ö†Ô∏è Please enter prescription details to analyze."

    # Create comprehensive prompt
    prompt = f"""You are an expert medical AI assistant specializing in prescription verification.
Analyze the following prescription and provide a detailed verification report.

PRESCRIPTION DETAILS:
{prescription_text}

PATIENT INFORMATION:
- Age: {patient_age} years
- Weight: {patient_weight} kg
- Known Allergies: {allergies if allergies else "None reported"}

Please provide a comprehensive analysis covering:
1. **Medication Verification**: Check if medications are appropriate for the condition
2. **Dosage Assessment**: Verify if dosages are within safe ranges for patient's age and weight
3. **Drug Interactions**: Identify potential interactions between prescribed medications
4. **Allergy Warnings**: Check for contraindications based on patient allergies
5. **Safety Concerns**: Highlight any red flags or safety issues
6. **Recommendations**: Provide suggestions for the healthcare provider

Format your response clearly with sections and be specific."""

    try:
        # Tokenize input
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1024)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        # Generate response
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=800,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id
            )

        # Decode response
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        # Extract only the generated part (after the prompt)
        if prompt in response:
            response = response.split(prompt)[1].strip()

        if not response:
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        return response

    except Exception as e:
        return f"‚ùå Error during analysis: {str(e)}\n\nPlease try again or simplify your input."


def check_drug_interaction(drug1, drug2):
    """
    Check potential interaction between two drugs
    """

    if not drug1.strip() or not drug2.strip():
        return "‚ö†Ô∏è Please enter both medication names to check interaction."

    prompt = f"""As a medical AI expert, analyze the potential interaction between these two medications:

Drug 1: {drug1}
Drug 2: {drug2}

Provide:
1. Interaction Level (None/Minor/Moderate/Major/Severe)
2. Description of the interaction mechanism
3. Clinical implications
4. Recommendations for healthcare providers
5. Monitoring requirements if prescribed together

Be specific and evidence-based."""

    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=600,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        if prompt in response:
            response = response.split(prompt)[1].strip()

        if not response:
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        return response

    except Exception as e:
        return f"‚ùå Error during analysis: {str(e)}\n\nPlease try again."


def dosage_calculator(medication, patient_age, patient_weight, condition):
    """
    Calculate appropriate dosage based on patient parameters
    """

    if not medication.strip():
        return "‚ö†Ô∏è Please enter a medication name."

    prompt = f"""As a clinical pharmacology expert, calculate the appropriate dosage for:

Medication: {medication}
Patient Age: {patient_age} years
Patient Weight: {patient_weight} kg
Medical Condition: {condition}

Provide:
1. Recommended dosage range
2. Frequency of administration
3. Route of administration
4. Maximum daily dose
5. Special considerations for this patient
6. Dosage adjustments if needed

Base recommendations on standard clinical guidelines."""

    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=500,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        if prompt in response:
            response = response.split(prompt)[1].strip()

        if not response:
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        return response

    except Exception as e:
        return f"‚ùå Error during analysis: {str(e)}\n\nPlease try again."


# ============================================================================
# STEP 5: Create Gradio Interface
# ============================================================================

print("üé® Creating Gradio Interface...\n")

# Custom CSS for better styling
custom_css = """
.container {
    max-width: 1200px;
    margin: auto;
}
.header {
    text-align: center;
    padding: 20px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    margin-bottom: 20px;
}
"""

# Create the main interface with tabs
with gr.Blocks(css=custom_css, theme=gr.themes.Soft(), title="AI Medical Prescription Verification") as demo:

    gr.HTML("""
        <div class="header">
            <h1>üè• AI Medical Prescription Verification System</h1>
            <p>Powered by IBM Granite 3.0 2B Instruct Model</p>
            <p style="font-size: 0.9em; opacity: 0.9;">‚ö†Ô∏è For Educational/Research Purposes Only - Not a Replacement for Professional Medical Advice</p>
        </div>
    """)

    with gr.Tabs():

        # Tab 1: Prescription Verification
        with gr.Tab("üìã Prescription Verification"):
            gr.Markdown("### Comprehensive Prescription Analysis")

            with gr.Row():
                with gr.Column():
                    prescription_input = gr.Textbox(
                        label="Prescription Details",
                        placeholder="Enter complete prescription:\ne.g., Amoxicillin 500mg, 3 times daily for 7 days\nIbuprofen 400mg, as needed for pain",
                        lines=6
                    )
                    age_input = gr.Number(label="Patient Age (years)", value=30, minimum=0, maximum=120)
                    weight_input = gr.Number(label="Patient Weight (kg)", value=70, minimum=1, maximum=300)
                    allergies_input = gr.Textbox(
                        label="Known Allergies",
                        placeholder="e.g., Penicillin, Sulfa drugs (leave empty if none)"
                    )
                    verify_btn = gr.Button("üîç Verify Prescription", variant="primary", size="lg")

                with gr.Column():
                    verification_output = gr.Textbox(
                        label="Verification Report",
                        lines=20,
                        show_copy_button=True
                    )

            verify_btn.click(
                fn=verify_prescription,
                inputs=[prescription_input, age_input, weight_input, allergies_input],
                outputs=verification_output
            )

            gr.Examples(
                examples=[
                    ["Metformin 500mg twice daily\nLisinopril 10mg once daily", 55, 85, ""],
                    ["Amoxicillin 500mg three times daily for 10 days", 8, 25, "Penicillin"],
                    ["Warfarin 5mg daily\nAspirin 81mg daily", 70, 75, "None"]
                ],
                inputs=[prescription_input, age_input, weight_input, allergies_input]
            )

        # Tab 2: Drug Interaction Checker
        with gr.Tab("‚ö†Ô∏è Drug Interaction Checker"):
            gr.Markdown("### Check Potential Drug-Drug Interactions")

            with gr.Row():
                with gr.Column():
                    drug1_input = gr.Textbox(label="First Medication", placeholder="e.g., Warfarin")
                    drug2_input = gr.Textbox(label="Second Medication", placeholder="e.g., Aspirin")
                    interaction_btn = gr.Button("üî¨ Check Interaction", variant="primary", size="lg")

                with gr.Column():
                    interaction_output = gr.Textbox(
                        label="Interaction Analysis",
                        lines=15,
                        show_copy_button=True
                    )

            interaction_btn.click(
                fn=check_drug_interaction,
                inputs=[drug1_input, drug2_input],
                outputs=interaction_output
            )

            gr.Examples(
                examples=[
                    ["Warfarin", "Aspirin"],
                    ["Metformin", "Alcohol"],
                    ["Lisinopril", "Potassium supplements"]
                ],
                inputs=[drug1_input, drug2_input]
            )

        # Tab 3: Dosage Calculator
        with gr.Tab("üíä Dosage Calculator"):
            gr.Markdown("### Calculate Appropriate Medication Dosage")

            with gr.Row():
                with gr.Column():
                    med_input = gr.Textbox(label="Medication Name", placeholder="e.g., Amoxicillin")
                    calc_age_input = gr.Number(label="Patient Age (years)", value=30, minimum=0, maximum=120)
                    calc_weight_input = gr.Number(label="Patient Weight (kg)", value=70, minimum=1, maximum=300)
                    condition_input = gr.Textbox(label="Medical Condition", placeholder="e.g., Bacterial infection")
                    dosage_btn = gr.Button("üìä Calculate Dosage", variant="primary", size="lg")

                with gr.Column():



# AI Medical Prescription Verification System
# Using IBM Granite 3.0 2B Instruct + Gradio Interface
# Ready for Google Colab - Single Cell Execution

import subprocess
import sys

print("üì¶ Installing required packages...")
subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "gradio", "gradio_client"], capture_output=True, check=False)
packages = ["gradio==4.44.1", "transformers", "torch", "accelerate", "bitsandbytes", "sentencepiece", "protobuf"]
for package in packages:
    print(f"Installing {package}...")
    subprocess.run([sys.executable, "-m", "pip", "install", "-q", package], capture_output=True, check=False)
print("\n‚úÖ All packages installed successfully!")

try:
    import gradio as gr
    print("‚úÖ Gradio imported successfully - continuing...\n")
except ImportError:
    print("\n‚ö†Ô∏è  Runtime restart required!")
    print("="*70)
    print("1. Click 'Runtime' ‚Üí 'Restart runtime' in the menu")
    print("2. After restart, run this cell again")
    print("="*70)
    raise SystemExit("Runtime restart needed")

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import warnings
warnings.filterwarnings('ignore')

print("üìö Libraries imported successfully!\n")
print("üîÑ Loading IBM Granite 3.0 2B Instruct model...\n")

model_name = "ibm-granite/granite-3.0-2b-instruct"
quantization_config = BitsAndBytesConfig(load_in_8bit=True, bnb_8bit_compute_dtype=torch.float16)

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quantization_config, device_map="auto", trust_remote_code=True)
    print("‚úÖ Model loaded successfully!\n")
except Exception as e:
    print(f"‚ö†Ô∏è  Error with quantization, trying without...")
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", trust_remote_code=True, torch_dtype=torch.float16)
    print("‚úÖ Model loaded successfully!\n")

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

def verify_prescription(prescription_text, patient_age, patient_weight, allergies):
    if not prescription_text.strip():
        return "‚ö†Ô∏è Please enter prescription details to analyze."

    prompt = f"""You are an expert medical AI assistant specializing in prescription verification.
Analyze the following prescription and provide a detailed verification report.

PRESCRIPTION DETAILS:
{prescription_text}

PATIENT INFORMATION:
- Age: {patient_age} years
- Weight: {patient_weight} kg
- Known Allergies: {allergies if allergies else "None reported"}

Please provide analysis covering:
1. Medication Verification
2. Dosage Assessment
3. Drug Interactions
4. Allergy Warnings
5. Safety Concerns
6. Recommendations"""

    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1024)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = model.generate(**inputs, max_new_tokens=800, temperature=0.7, top_p=0.9, do_sample=True, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        if prompt in response:
            response = response.split(prompt)[1].strip()
        if not response:
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return response
    except Exception as e:
        return f"‚ùå Error: {str(e)}"

def check_drug_interaction(drug1, drug2):
    if not drug1.strip() or not drug2.strip():
        return "‚ö†Ô∏è Please enter both medication names."

    prompt = f"""As a medical AI expert, analyze the interaction between:
Drug 1: {drug1}
Drug 2: {drug2}

Provide:
1. Interaction Level
2. Mechanism
3. Clinical implications
4. Recommendations
5. Monitoring requirements"""

    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = model.generate(**inputs, max_new_tokens=600, temperature=0.7, top_p=0.9, do_sample=True, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)
        response = tokenizer.deco

!pip install a gradio Hugging face

# AI Medical Prescription Verification System
# Using IBM Granite 3.0 2B Instruct + Gradio Interface
# Ready for Google Colab - Single Cell Execution

import subprocess
import sys

print("üì¶ Installing required packages...")
subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "gradio", "gradio_client"], capture_output=True, check=False)
packages = ["gradio==4.44.1", "transformers", "torch", "accelerate", "bitsandbytes", "sentencepiece", "protobuf"]
for package in packages:
    print(f"Installing {package}...")
    subprocess.run([sys.executable, "-m", "pip", "install", "-q", package], capture_output=True, check=False)
print("\n‚úÖ All packages installed successfully!")

try:
    import gradio as gr
    print("‚úÖ Gradio imported successfully - continuing...\n")
except ImportError:
    print("\n‚ö†Ô∏è  Runtime restart required!")
    print("="*70)
    print("1. Click 'Runtime' ‚Üí 'Restart runtime' in the menu")
    print("2. After restart, run this cell again")
    print("="*70)
    raise SystemExit("Runtime restart needed")

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import warnings
warnings.filterwarnings('ignore')

print("üìö Libraries imported successfully!\n")
print("üîÑ Loading IBM Granite 3.0 2B Instruct model...\n")

model_name = "ibm-granite/granite-3.0-2b-instruct"
quantization_config = BitsAndBytesConfig(load_in_8bit=True, bnb_8bit_compute_dtype=torch.float16)

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quantization_config, device_map="auto", trust_remote_code=True)
    print("‚úÖ Model loaded successfully!\n")
except Exception as e:
    print(f"‚ö†Ô∏è  Error with quantization, trying without...")
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", trust_remote_code=True, torch_dtype=torch.float16)
    print("‚úÖ Model loaded successfully!\n")

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

def verify_prescription(prescription_text, patient_age, patient_weight, allergies):
    if not prescription_text.strip():
        return "‚ö†Ô∏è Please enter prescription details to analyze."

    prompt = f"""You are an expert medical AI assistant specializing in prescription verification.
Analyze the following prescription and provide a detailed verification report.

PRESCRIPTION DETAILS:
{prescription_text}

PATIENT INFORMATION:
- Age: {patient_age} years
- Weight: {patient_weight} kg
- Known Allergies: {allergies if allergies else "None reported"}

Please provide analysis covering:
1. Medication Verification
2. Dosage Assessment
3. Drug Interactions
4. Allergy Warnings
5. Safety Concerns
6. Recommendations"""

    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1024)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = model.generate(**inputs, max_new_tokens=800, temperature=0.7, top_p=0.9, do_sample=True, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        if prompt in response:
            response = response.split(prompt)[1].strip()
        if not response:
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return response
    except Exception as e:
        return f"‚ùå Error: {str(e)}"

def check_drug_interaction(drug1, drug2):
    if not drug1.strip() or not drug2.strip():
        return "‚ö†Ô∏è Please enter both medication names."

    prompt = f"""As a medical AI expert, analyze the interaction between:
Drug 1: {drug1}
Drug 2: {drug2}

Provide:
1. Interaction Level
2. Mechanism
3. Clinical implications
4. Recommendations
5. Monitoring requirements"""

    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = model.generate(**inputs, max_new_tokens=600, temperature=0.7, top_p=0.9, do_sample=True, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)
        response = tokenizer.deco

!pip install transformers accelerate gradio --quiet

# ===============================================================
# AI MEDICAL PRESCRIPTION VERIFICATION SYSTEM
# Leveraging IBM Granite 3.3 2B Instruct + Hugging Face + Gradio
# ===============================================================

# ----------------- INSTALL DEPENDENCIES -----------------
!pip install transformers accelerate gradio --quiet

# ----------------- IMPORT LIBRARIES ---------------------
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import gradio as gr
import torch

# ----------------- HUGGING FACE TOKEN -------------------
# IMPORTANT: Replace with your Hugging Face API Key
HF_TOKEN = "YOUR_HUGGINGFACE_API_KEY_HERE"

# ----------------- LOAD MODEL ---------------------------
model_name = "ibm-granite/granite-3.3-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=HF_TOKEN)

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto",
    use_auth_token=HF_TOKEN
)

pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=500,
    temperature=0.1,
    top_p=0.9
)

# ----------------- AI PROCESSING FUNCTION ---------------
def analyze_prescription(prescription, patient_age):
    prompt = f"""
You are a medical AI assistant specialized in prescription verification.
Analyze the prescription using medical reasoning. Your task:

### 1. Extract Drug Information (NLP)
- List medications
- Extract strength, dosage, frequency, and duration

### 2. Drug Interaction Check
- Identify possible interactions between medications
- Explain severity (mild, moderate, severe)

### 3. Age-Specific Dosage Analysis
- Check whether dosage fits a patient aged {patient_age}
- Mention if dosage is too high, too low, or appropriate

### 4. Suggest Alternative Medications
- Suggest safer or equivalent alternatives if needed
- Explain why they may be beneficial

### 5. Summarize Overall Prescription Safety
- Give a final verdict (SAFE / NEEDS REVIEW / UNSAFE)

### Prescription to evaluate:
\"\"\"{prescription}\"\"\"

Respond in a clear, structured medical report format.
IMPORTANT: Do NOT give actual medical advice. Only analyze based on general information.
"""

    result = pipe(prompt)[0]["generated_text"]
    return result


# ----------------- GRADIO INTERFACE ---------------------
ui = gr.Interface(
    fn=analyze_prescription,
    inputs=[
        gr.Textbox(label="Enter Prescription Text", lines=8, placeholder="e.g., Amoxicillin 500 mg twice daily + Ibuprofen 400 mg as needed"),
        gr.Number(label="Patient Age", value=30)
    ],
    outputs=gr.Textbox(label="AI Medical Analysis Report", lines=20),
    title="AI Medical Prescription Verification",
    description="Powered by IBM Granite 3.3 2B Instruct + Hugging Face",
)

# ----------------- LAUNCH APP ---------------------------
ui.launch()